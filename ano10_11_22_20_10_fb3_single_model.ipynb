{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "042df8cd",
      "metadata": {
        "id": "042df8cd"
      },
      "source": [
        "# This notebook is for my learning.\n",
        "I have implemented the followings in pytorch.\n",
        "* Layer-Wise Learning Rate Dacay\n",
        "* Attention pooling\n",
        "* WeightedLayerPooling\n",
        "* Fast Gradient Method\n",
        "* Adversarial Weight Perturbation\n",
        "* Re-initializing upper layer (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal)\n",
        "* Initializing module (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal)\n",
        "* Freeze lower layer when you use very large model (v2-xlarge, funnnel, etc.)\n",
        "* Loss function, SmoothL1 or RMSE\n",
        "\n",
        "\n",
        "I will continue to update it if time allows.  \n",
        "And if you like this notebook, please upvote it. Thank you in advance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03b9ea44",
      "metadata": {
        "id": "03b9ea44"
      },
      "source": [
        "If you have time, please check my other notebooks.\n",
        "\n",
        "* Inference : https://www.kaggle.com/kojimar/fb3-single-pytorch-model-inference\n",
        "* Ensemble : https://www.kaggle.com/code/kojimar/fb3-deberta-family-inference-9-28-updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T7ElgwblPQVJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7ElgwblPQVJ",
        "outputId": "47d79d01-7eae-481f-b1dd-c8dbcd545447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "開始時間：  2022-11-22 20:48:16.400736\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(\"開始時間： \", datetime.datetime.now() + datetime.timedelta(hours=9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fx5VAeVxtAGI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx5VAeVxtAGI",
        "outputId": "56064bd6-0b43-4cf3-ebac-9028a02ed7a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 22 11:48:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ySGaHVjzXjDI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySGaHVjzXjDI",
        "outputId": "6efbe6de-aa19-4736-ef6b-2189da90dfdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "google colaboratory環境です！\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Mounted at /content/drive\n",
            "Downloading feedback-prize-english-language-learning.zip to ../input\n",
            "  0% 0.00/2.80M [00:00<?, ?B/s]\n",
            "100% 2.80M/2.80M [00:00<00:00, 76.5MB/s]\n",
            "Archive:  ../input/feedback-prize-english-language-learning.zip\n",
            "  inflating: ../input/feedback-prize-english-language-learning/sample_submission.csv  \n",
            "  inflating: ../input/feedback-prize-english-language-learning/test.csv  \n",
            "  inflating: ../input/feedback-prize-english-language-learning/train.csv  \n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.21.2\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (4.13.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.2) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 66.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.21.2) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.21.2) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.2) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.12.1 transformers-4.21.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import json\n",
        "\n",
        "if 'google.colab' in sys.modules:  # colab環境\n",
        "    # INPUT = Path(‘/content/input/’)\n",
        "    print('google colaboratory環境です！')\n",
        "    # if not os.path.exists('/content/train.csv'):\n",
        "    if not os.path.exists('../input/feedback-prize-english-language-learning/train.csv'):\n",
        "        !pip install kaggle\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        f = open(\"/content/drive/MyDrive/kaggle.json\", 'r')\n",
        "        json_data = json.load(f) \n",
        "        os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "        os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "\n",
        "        !kaggle competitions download -c feedback-prize-english-language-learning -p '../input'\n",
        "        # !kaggle datasets download -d yasufuminakama/fb3-pip-wheels -p '/content/datasets'\n",
        "        # !unzip '/content/feedback-prize-english-language-learning.zip'\n",
        "        # !unzip '../input/feedback-prize-english-language-learning.zip'\n",
        "        !unzip -o '../input/feedback-prize-english-language-learning.zip' -d '../input/feedback-prize-english-language-learning' # -oオプションですでに解凍済みファイルがあっても強制的に上書きする。-dで展開先ディレクトリを指定。\n",
        "\n",
        "        !pip install transformers==4.21.2\n",
        "        !pip install tokenizers==0.12.1\n",
        "        !pip install sentencepiece\n",
        "\n",
        "        # # 使用するデータセットをダウンロード\n",
        "        # if not os.path.exists('/content/datasets'):\n",
        "\n",
        "        #     !kaggle datasets download -d kojimar/fb3models -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d randyli2/bert-shopping-mall -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d hiromoon166/deberta-v3-large -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d tabchenjlu/facebook-bart-large-mnli -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d quangphm/fb3embeddings -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d tdjogi010/hugging-face-gpt2 -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d sauravmaheshkar/huggingface-deberta-variants -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d lucca9211/iterativestratification -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d yzdivergence/muppet-roberta-large -p '/content/datasets' --unzip\n",
        "        #     !kaggle datasets download -d yasufuminakama/fb3-pip-wheels -p '/content/datasets' --unzip\n",
        "\n",
        "    # このノートブック名を取得\n",
        "    from requests import get\n",
        "    name_notebook = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n",
        "\n",
        "elif 'kaggle_web_client' in sys.modules:  # kaggle環境\n",
        "    print('kaggle環境です！')\n",
        "    # INPUT = Path(‘../input/’)\n",
        "    pass\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ae051a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ae051a",
        "outputId": "74467e86-6dcb-477a-eb6c-bc1974de1ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformers.__version__: 4.21.2\n",
            "tokenizers.__version__: 0.12.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import re\n",
        "import ast\n",
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import math\n",
        "import string\n",
        "import pickle\n",
        "import random\n",
        "import joblib\n",
        "import itertools\n",
        "from distutils.util import strtobool\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "\n",
        "from pdb import set_trace as st\n",
        "\n",
        "import transformers\n",
        "import tokenizers\n",
        "print(f'transformers.__version__: {transformers.__version__}')\n",
        "print(f'tokenizers.__version__: {tokenizers.__version__}')\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "os.environ['TOKENIZERS_PARALLELISM']='true'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8d61dc",
      "metadata": {
        "id": "bd8d61dc"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1H01Nzb6Jgvy",
      "metadata": {
        "id": "1H01Nzb6Jgvy"
      },
      "outputs": [],
      "source": [
        "# ver_title = \"AttentionPool(GERU) FGM=True\"\n",
        "# ver_title = \"AttPool(Tanh) FGM=False\"\n",
        "# ver_title = \"AtPool(Tanh) FGM maxlen=1024\"\n",
        "# ver_title = \"AtPool(Tanh) FGM reinit_n=2\" # maxlen=512\n",
        "# ver_title = \"AtPool(Tanh) FGM xavier_uni\" # maxlen=512\n",
        "# ver_title = \"AtPool(Tanh) FGM pretrain=False\" # maxlen=512\n",
        "# ver_title = \"APo(Th)FGM 768　kaiming_uniform\"\n",
        "# ver_title = \"APo(Th)FGM 768　kaiming_normal\"\n",
        "# ver_title = \"APo(Th)FGM 768　normal 10(scaled)\"\n",
        "# ver_title = \"APo(Th) 768　normal lrd85\"\n",
        "# ver_title = \"APo(Th) 768　normal lrd95\"\n",
        "# ver_title = \"APo(Th) normal maxlen=None\"\n",
        "ver_title = \"APo(Th) weight=orthogonal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5bdb746",
      "metadata": {
        "id": "a5bdb746"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    str_now = (datetime.datetime.now() + datetime.timedelta(hours=9)).strftime('%Y%m%d-%H%M%S')\n",
        "    train = True\n",
        "    debug = False\n",
        "    offline = False\n",
        "    models_path = 'FB3-models'\n",
        "    epochs = 5\n",
        "    # epochs = 4\n",
        "    save_all_models = False\n",
        "    competition = 'FB3'\n",
        "    apex = True\n",
        "    print_freq = 20\n",
        "    num_workers = 4\n",
        "    model = 'microsoft/deberta-v3-base' #If you want to train on the kaggle platform, v3-base is realistic. v3-large will time out.\n",
        "    loss_func = 'SmoothL1' # 'SmoothL1', 'RMSE'\n",
        "    gradient_checkpointing = True\n",
        "    scheduler = 'cosine'\n",
        "    batch_scheduler = True\n",
        "    num_cycles = 0.5\n",
        "    num_warmup_steps = 0\n",
        "    encoder_lr = 2e-5\n",
        "    decoder_lr = 2e-5\n",
        "    min_lr = 1e-6\n",
        "    #Layer-Wise Learning Rate Decay\n",
        "    llrd = True\n",
        "    layerwise_lr = 5e-5\n",
        "    # layerwise_lr = 5e-8 # 変更している\n",
        "    layerwise_lr_decay = 0.9\n",
        "    # layerwise_lr_decay = 0.85 # 変更している\n",
        "    # layerwise_lr_decay = 0.95 # 変更している\n",
        "    layerwise_weight_decay = 0.01\n",
        "    layerwise_adam_epsilon = 1e-6\n",
        "    layerwise_use_bertadam = False\n",
        "    #pooling\n",
        "    # TODO: weightedlayerを試す！！！！！！！！\n",
        "    # pooling = 'mean' # mean, max, min, attention, weightedlayer\n",
        "    # pooling = 'weightedlayer'\n",
        "    pooling = 'attention' # mean, max, min, attention, weightedlayer\n",
        "    # TODO: 9とか12とかも試してみる\n",
        "    layer_start = 4\n",
        "    # layer_start = 9\n",
        "    # fgm = False\n",
        "    fgm = True\n",
        "    awp = False\n",
        "    # awp = True\n",
        "    # TODO: 変更してみる！！！\n",
        "    # こんにちは。特に1000でなければならない理由はありません。私が実験した限りでは、ノルムを小さくするとCVは向上しますが、LBは悪化します。\n",
        "    max_grad_norm = 1000\n",
        "    # max_grad_norm = 6554\n",
        "    # max_grad_norm = 10\n",
        "    unscale = False\n",
        "    # unscale = True\n",
        "    #init_weight\n",
        "    # init_weight = 'normal' # normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal\n",
        "    init_weight = 'orthogonal'\n",
        "    # use_pretrained = False\n",
        "    use_pretrained = True\n",
        "    #re-init\n",
        "    reinit = True\n",
        "    # TODO: 2層をreinitializeしてみる\n",
        "    reinit_n = 1\n",
        "    # reinit_n = 2\n",
        "    #adversarial\n",
        "    adv_lr = 1\n",
        "    adv_eps = 0.2\n",
        "    eps = 1e-6\n",
        "    betas = (0.9, 0.999)\n",
        "    # max_len = 512\n",
        "    max_len = 768\n",
        "    # max_len = 1024\n",
        "    weight_decay = 0.01\n",
        "    gradient_accumulation_steps = 1\n",
        "    target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
        "    seed = 42\n",
        "    cv_seed = 42\n",
        "    # seed = 2022\n",
        "    # cv_seed = 2022\n",
        "    # TODO: 10foldの方が良いのかも...\n",
        "    n_fold = 4\n",
        "    trn_fold = list(range(n_fold))\n",
        "    batch_size = 8\n",
        "    n_targets = 6\n",
        "    gpu_id = 0\n",
        "    device = f'cuda:{gpu_id}'\n",
        "    train_file = '../input/feedback-prize-english-language-learning/train.csv'\n",
        "    test_file = '../input/feedback-prize-english-language-learning/test.csv'\n",
        "    submission_file = '../input/feedback-prize-english-language-learning/sample_submission.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35118197",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35118197",
        "outputId": "81093689-a29a-4023-85ad-4f46ddf0b799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20221122-204903-deberta-v3-base\n"
          ]
        }
      ],
      "source": [
        "#Unique model name\n",
        "if len(CFG.model.split(\"/\")) == 2:\n",
        "    CFG.identifier = f'{CFG.str_now}-{CFG.model.split(\"/\")[1]}'\n",
        "else:\n",
        "    CFG.identifier = f'{CFG.str_now}-{CFG.model}'\n",
        "\n",
        "# CFG.identifier = 'made-models-of-deberta-v3-base'\n",
        "    \n",
        "print(CFG.identifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4l6T74vRmRAx",
      "metadata": {
        "id": "4l6T74vRmRAx"
      },
      "outputs": [],
      "source": [
        "# ################################\n",
        "# nunique_tokenの実装\n",
        "# ################################\n",
        "# def get_text_token_cnts(\n",
        "#     df: pd.DataFrame,\n",
        "#     tokenizer,\n",
        "#     inplace: bool = False\n",
        "# ):\n",
        "#     token_cnts = []\n",
        "#     for text in tqdm(df[\"full_text\"], total=len(df)):\n",
        "#         input_ids = tokenizer(\n",
        "#             text,\n",
        "#             add_special_tokens=False,\n",
        "#             return_token_type_ids=False,\n",
        "#             return_attention_mask=False\n",
        "#         )[\"input_ids\"]\n",
        "#         token_cnts.append([len(input_ids), len(set(input_ids))])\n",
        "#     if not inplace:\n",
        "#         df = df.copy()\n",
        "#     df[[\"n_token\", \"nunique_token\"]] = token_cnts\n",
        "#     return df\n",
        "\n",
        "# # train_df = pd.read_csv(f\"{CFG.data_dir}/train.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10683c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b10683c9",
        "outputId": "bf595ee8-1760-4468-865f-ecd44f9498b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./20221122-204903-deberta-v3-base/\n"
          ]
        }
      ],
      "source": [
        "if CFG.train:\n",
        "    CFG.df_train = pd.read_csv(CFG.train_file)\n",
        "\n",
        "    #################################\n",
        "    # nunique_tokenの実装\n",
        "    #################################\n",
        "    # CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
        "    # CFG.tokenizer.save_pretrained(CFG.OUTPUT_DIR + 'tokenizer')\n",
        "\n",
        "    # train_df = get_text_token_cnts(CFG.df_train, CFG.tokenizer, inplace=False)\n",
        "    # N_TOKEN_BIN = 50\n",
        "    # N_UNIQUE_TOKEN_BIN = 50\n",
        "    # train_df[\"n_token_bin\"] = pd.qcut(\n",
        "    #     x=train_df[\"n_token\"], q=N_TOKEN_BIN, labels=False, duplicates=\"drop\"\n",
        "    # )\n",
        "    # train_df[\"nutoken_bin\"] = pd.qcut(\n",
        "    #     x=train_df[\"nunique_token\"], q=N_UNIQUE_TOKEN_BIN, labels=False, duplicates=\"drop\"\n",
        "    # )\n",
        "\n",
        "\n",
        "    CFG.OUTPUT_DIR = f'./{CFG.identifier}/'\n",
        "    CFG.log_filename = CFG.OUTPUT_DIR + 'train'\n",
        "    if CFG.offline:\n",
        "        #TO DO\n",
        "        pass\n",
        "    else:\n",
        "        os.system('pip install iterative-stratification==0.1.7')\n",
        "    #CV\n",
        "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold    \n",
        "    Fold = MultilabelStratifiedKFold(n_splits = CFG.n_fold, shuffle = True, random_state = CFG.cv_seed)\n",
        "\n",
        "    for n, (train_index, val_index) in enumerate(Fold.split(CFG.df_train, CFG.df_train[CFG.target_cols])):\n",
        "    # for n, (train_index, val_index) in enumerate(Fold.split(CFG.df_train, CFG.df_train[CFG.target_cols + [\"n_token_bin\", \"nutoken_bin\"]])):\n",
        "\n",
        "\n",
        "        CFG.df_train.loc[val_index, 'fold'] = int(n)\n",
        "    CFG.df_train['fold'] = CFG.df_train['fold'].astype(int)\n",
        "else:\n",
        "    #TO DO\n",
        "    pass\n",
        "\n",
        "if CFG.debug:\n",
        "    CFG.epochs = 2\n",
        "    CFG.trn_fold = [0]\n",
        "    if CFG.train:\n",
        "        CFG.df_train = CFG.df_train.sample(n = 100, random_state = CFG.seed).reset_index(drop=True)\n",
        "        \n",
        "os.makedirs(CFG.OUTPUT_DIR, exist_ok=True)    \n",
        "print(CFG.OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IKukPzdsbkF7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKukPzdsbkF7",
        "outputId": "68b0fe89-926d-4162-b725-fb4923b202df"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# %cdで/rootに移動できる。/root/.kaggle にkaggle.jsonを配置しなくてはいけないっぽいから、/root/.kaggleディレクトリ作って、そこにkaggle.jsonを配置して、その後もとの/contentに戻っている\n",
        "%cd\n",
        "!mkdir .kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json .kaggle/\n",
        "%cd /content\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# 環境変数設定\n",
        "%env KAGGLE_USERNAME=\"\"\n",
        "\n",
        "PRETRAIN_DIR = Path(CFG.OUTPUT_DIR)\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "# dataset-metadata.jsonを作成\n",
        "api.dataset_initialize_cli(folder=PRETRAIN_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364e9c27",
      "metadata": {
        "id": "364e9c27"
      },
      "source": [
        "# Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6dcaba",
      "metadata": {
        "id": "9d6dcaba"
      },
      "outputs": [],
      "source": [
        "def MCRMSE(y_trues, y_preds):\n",
        "    scores = []\n",
        "    idxes = y_trues.shape[1]\n",
        "    for i in range(idxes):\n",
        "        y_true = y_trues[:, i]\n",
        "        y_pred = y_preds[:, i]\n",
        "        score = mean_squared_error(y_true, y_pred, squared = False)\n",
        "        scores.append(score)\n",
        "    mcrmse_score = np.mean(scores)\n",
        "    return mcrmse_score, scores\n",
        "\n",
        "def get_score(y_trues, y_preds):\n",
        "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
        "    return mcrmse_score, scores\n",
        "\n",
        "def get_logger(filename = CFG.log_filename):\n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter('%(message)s'))\n",
        "    handler2 = FileHandler(filename = f'{filename}.log')\n",
        "    handler2.setFormatter(Formatter('%(message)s'))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "def prepare_input(cfg, text):\n",
        "    inputs = cfg.tokenizer.encode_plus(\n",
        "        text,\n",
        "        return_tensors = None,\n",
        "        add_special_tokens = True,\n",
        "        max_length = cfg.max_len,\n",
        "        pad_to_max_length = True,\n",
        "        truncation = True\n",
        "    )\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
        "    return inputs\n",
        "\n",
        "\n",
        "\n",
        "# def prepare_input(cfg, text):\n",
        "#     inputs = cfg.tokenizer.encode_plus(\n",
        "#         text,\n",
        "#         return_tensors=None,\n",
        "#         return_token_type_ids=False,\n",
        "#         add_special_tokens=True,\n",
        "#         max_length=None,\n",
        "#         truncation=False,\n",
        "\n",
        "#     )\n",
        "#     for k, v in inputs.items():\n",
        "#         inputs[k] = torch.tensor(v, dtype=torch.long)\n",
        "#     return inputs  \n",
        "\n",
        "\n",
        "\n",
        "def collate(inputs):\n",
        "    mask_len = int(inputs['attention_mask'].sum(axis = 1).max())\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = inputs[k][:, :mask_len]\n",
        "    return inputs\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "        \n",
        "    def update(self, val, n = 1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{int(m)}m {int(s)}s'\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return f'{str(asMinutes(s))} (remain {str(asMinutes(rs))})'\n",
        "\n",
        "def seed_everything(seed = 42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, reduction = 'mean', eps = 1e-9):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss(reduction = 'none')\n",
        "        self.reduction = reduction\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n",
        "        if self.reduction == 'none':\n",
        "            loss = loss\n",
        "        elif self.reduction == 'sum':\n",
        "            loss = loss.sum()\n",
        "        elif self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "        return loss\n",
        "    \n",
        "seed_everything(CFG.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55633022",
      "metadata": {
        "id": "55633022"
      },
      "source": [
        "# Pooling\n",
        "\n",
        "* Attention pooling (https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678)\n",
        "* WeightedLayerPooling (https://www.kaggle.com/code/rhtsingh/on-stability-of-few-sample-transformer-fine-tuning?scriptVersionId=67176591&cellId=19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed191bd8",
      "metadata": {
        "id": "ed191bd8"
      },
      "outputs": [],
      "source": [
        "class MeanPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MeanPooling, self).__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
        "        mean_embeddings = sum_embeddings/sum_mask\n",
        "        return mean_embeddings\n",
        "\n",
        "class MaxPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MaxPooling, self).__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        embeddings = last_hidden_state.clone()\n",
        "        embeddings[input_mask_expanded == 0] = -1e4\n",
        "        max_embeddings, _ = torch.max(embeddings, dim = 1)\n",
        "        return max_embeddings\n",
        "    \n",
        "class MinPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MinPooling, self).__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        embeddings = last_hidden_state.clone()\n",
        "        embeddings[input_mask_expanded == 0] = 1e-4\n",
        "        min_embeddings, _ = torch.min(embeddings, dim = 1)\n",
        "        return min_embeddings\n",
        "\n",
        "#Attention pooling\n",
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "        nn.Linear(in_dim, in_dim),\n",
        "        nn.LayerNorm(in_dim),\n",
        "        # nn.GELU(),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(in_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        w = self.attention(last_hidden_state).float()\n",
        "        w[attention_mask==0]=float('-inf')\n",
        "        w = torch.softmax(w,1)\n",
        "        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n",
        "        return attention_embeddings\n",
        "\n",
        "#There may be a bug in my implementation because it does not work well.\n",
        "class WeightedLayerPooling(nn.Module):\n",
        "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
        "        super(WeightedLayerPooling, self).__init__()\n",
        "        self.layer_start = layer_start\n",
        "        # num_hidden_layers = 12\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        # 埋め込み層の出力も受け取っているため、モデルでは隠れ層が12層あるにもかかわらず、隠れ層の出力は13層になっています。\n",
        "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
        "            else nn.Parameter(\n",
        "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
        "            )\n",
        "\n",
        "    def forward(self, ft_all_layers):\n",
        "        all_layer_embedding = torch.stack(ft_all_layers)\n",
        "        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :] # n層目以降のembedding層だけ\n",
        "\n",
        "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
        "        # 特定の重み（weight_factor）をlayer_startで指定した層より後の層全てに掛け合わせて、そしてlayer_weightsを合計で割って平均を算出する。\n",
        "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
        "\n",
        "        return weighted_average\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92707e50",
      "metadata": {
        "id": "92707e50"
      },
      "source": [
        "# Fast Gradient Method (FGM)\n",
        "Reference :\n",
        "\n",
        "https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143764\n",
        "\n",
        "https://blog.brainpad.co.jp/entry/2022/08/23/153001#:~:text=FGM%EF%BC%88Fast%20Gradient%20Method%EF%BC%89,-FGM%E3%81%A7%E3%81%AF%E3%80%81%E5%AD%A6%E7%BF%92&text=%E5%AD%A6%E7%BF%92%E3%81%AE%E5%90%84step%E3%81%8A,%E3%81%93%E3%81%A8%E3%81%8C%E5%8F%AF%E8%83%BD%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857cb5c4",
      "metadata": {
        "id": "857cb5c4"
      },
      "outputs": [],
      "source": [
        "class FGM():\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.backup = {}\n",
        "\n",
        "    def attack(self, epsilon = 1., emb_name = 'word_embeddings'):\n",
        "        \"\"\"\n",
        "        敵対的な摂動(小さな攪乱(かくらん)・ずれ。)を求め、現在のembedding layerに摂動を加える\n",
        "        \"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and emb_name in name:\n",
        "                self.backup[name] = param.data.clone()\n",
        "                norm = torch.norm(param.grad)\n",
        "                if norm != 0:\n",
        "                    r_at = epsilon * param.grad / norm\n",
        "                    param.data.add_(r_at)\n",
        "\n",
        "    def restore(self, emb_name = 'word_embeddings'):\n",
        "        \"\"\"\n",
        "        敵対的な摂動を求める際に変更してしまったembedding layerのパラメータについて\n",
        "        元のパラメータを代入する\n",
        "        \"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and emb_name in name:\n",
        "                assert name in self.backup\n",
        "                param.data = self.backup[name]\n",
        "            self.backup = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466b0768",
      "metadata": {
        "id": "466b0768"
      },
      "source": [
        "# Adversarial Weight Perturbation (AWP)\n",
        "There may be a bug in my implementation because it does not work well.\n",
        "\n",
        "Reference : \n",
        "\n",
        "https://www.kaggle.com/code/wht1996/feedback-nn-train/notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21375aec",
      "metadata": {
        "id": "21375aec"
      },
      "outputs": [],
      "source": [
        "# FGMにおいては、敵対的な摂動はモデルの入力（入力の埋め込み表現）に対して加えられることになりますが、摂動をモデルの「入力」ではなくモデルの「重み」に加える、という方法も考えられます。\n",
        "# この方法として代表的なのがAWP（Adversarial Weight Perturbation）です。\n",
        "class AWP:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        optimizer,\n",
        "        adv_param=\"weight\",\n",
        "        adv_lr=1,\n",
        "        adv_eps=0.2,\n",
        "        start_epoch=0,\n",
        "        adv_step=1,\n",
        "        scaler=None\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.adv_param = adv_param\n",
        "        self.adv_lr = adv_lr\n",
        "        self.adv_eps = adv_eps\n",
        "        self.start_epoch = start_epoch\n",
        "        self.adv_step = adv_step\n",
        "        self.backup = {}\n",
        "        self.backup_eps = {}\n",
        "        self.scaler = scaler\n",
        "        \n",
        "    # def attack_backward(self, x, y, attention_mask,epoch):\n",
        "    #     \"\"\"\n",
        "    #     敵対的な摂動を加えた損失を計算し、パラメータを更新する\n",
        "    #     \"\"\"\n",
        "    #     if (self.adv_lr == 0) or (epoch < self.start_epoch):\n",
        "    #         return None\n",
        "\n",
        "    #     self._save() \n",
        "    #     for i in range(self.adv_step):\n",
        "    #         self._attack_step() \n",
        "    #         with torch.cuda.amp.autocast():\n",
        "    #             adv_loss, tr_logits = self.model(input_ids=x, attention_mask=attention_mask, labels=y)\n",
        "    #             adv_loss = adv_loss.mean()\n",
        "    #         self.optimizer.zero_grad()\n",
        "    #         self.scaler.scale(adv_loss).backward()\n",
        "    #     self._restore()\n",
        "\n",
        "    # see: https://www.kaggle.com/code/kojimar/fb3-single-pytorch-model-train/comments#2017711\n",
        "    def attack_backward(self, x, y ,epoch):\n",
        "        \"\"\"\n",
        "        敵対的な摂動を加えた損失を計算し、パラメータを更新する\n",
        "        \"\"\"\n",
        "        if (self.adv_lr == 0) or (epoch < self.start_epoch):\n",
        "            return None\n",
        "        self._save() \n",
        "        for i in range(self.adv_step):\n",
        "            self._attack_step() \n",
        "            with torch.cuda.amp.autocast():\n",
        "                y_preds = self.model(x)\n",
        "                adv_loss = self.criterion(y_preds,y)\n",
        "                adv_loss = adv_loss.mean()\n",
        "            self.optimizer.zero_grad()\n",
        "            self.scaler.scale(adv_loss).backward()\n",
        "        self._restore()\n",
        "\n",
        "        \n",
        "    def _attack_step(self):\n",
        "        \"\"\"\n",
        "        敵対的な摂動を求め、重みに加える\n",
        "        重みの範囲をbackup_epsで制限している\n",
        "        \"\"\"\n",
        "        e = 1e-6\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
        "                norm1 = torch.norm(param.grad)\n",
        "                norm2 = torch.norm(param.data.detach())\n",
        "                if norm1 != 0 and not torch.isnan(norm1):\n",
        "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
        "                    param.data.add_(r_at)\n",
        "                    param.data = torch.min(\n",
        "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n",
        "                    )\n",
        "                # param.data.clamp_(*self.backup_eps[name])\n",
        "\n",
        "    def _save(self):\n",
        "        \"\"\"\n",
        "        重みのバックアップと、重みの範囲を取得する\n",
        "        重みの範囲はパラメータの絶対値とadv_epsによって決定する\n",
        "        \"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
        "                if name not in self.backup:\n",
        "                    self.backup[name] = param.data.clone()\n",
        "                    grad_eps = self.adv_eps * param.abs().detach()\n",
        "                    self.backup_eps[name] = (\n",
        "                        self.backup[name] - grad_eps,\n",
        "                        self.backup[name] + grad_eps,\n",
        "                    )\n",
        "\n",
        "    def _restore(self,):\n",
        "        \"\"\"\n",
        "        バックアップを取っていたパラメータを代入するとともに初期化する\n",
        "        \"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if name in self.backup:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "        self.backup_eps = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6bdf2ac",
      "metadata": {
        "id": "b6bdf2ac"
      },
      "source": [
        "# Train function\n",
        "* FGM\n",
        "* AWP (There may be a bug.)\n",
        "* Unscale optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a53dbdb",
      "metadata": {
        "id": "7a53dbdb"
      },
      "outputs": [],
      "source": [
        "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    losses = AverageMeter()\n",
        "    model.train()\n",
        "    # init_scale=4096 参考：https://qiita.com/bowdbeg/items/71c62cf8ef891d164ecd#%E6%B3%A8%E6%84%8F%E7%82%B9\n",
        "    # scaler = torch.cuda.amp.GradScaler(enabled = CFG.apex, init_scale=4096)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled = CFG.apex)\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    if CFG.fgm:\n",
        "        # embedding layerに敵対的な摂動を加える\n",
        "        fgm = FGM(model)\n",
        "    if CFG.awp:\n",
        "        awp = AWP(model,\n",
        "                  optimizer, \n",
        "                  adv_lr = CFG.adv_lr, \n",
        "                  adv_eps = CFG.adv_eps, \n",
        "                  scaler = scaler)\n",
        "    for step, (inputs, labels) in enumerate(train_loader):\n",
        "        attention_mask = inputs['attention_mask'].to(device)\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.cuda.amp.autocast(enabled = CFG.apex):\n",
        "            y_preds = model(inputs)\n",
        "            # 敵対的な摂動を加えられた状態での損失を計算\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        scaler.scale(loss).backward()\n",
        "        if CFG.unscale:\n",
        "            scaler.unscale_(optimizer)\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        \n",
        "        #Fast Gradient Method (FGM)\n",
        "        if CFG.fgm:\n",
        "            fgm.attack()\n",
        "            with torch.cuda.amp.autocast(enabled = CFG.apex):\n",
        "                y_preds = model(inputs)\n",
        "                loss_adv = criterion(y_preds, labels)\n",
        "                loss_adv.backward()\n",
        "            fgm.restore()\n",
        "            \n",
        "        #Adversarial Weight Perturbation (AWP)\n",
        "        if CFG.awp:\n",
        "            loss_awp = awp.attack_backward(inputs, labels, step + 1)\n",
        "            # loss_awp = awp.attack_backward(inputs, labels, attention_mask, step + 1)\n",
        "            loss_awp.backward()\n",
        "            awp._restore()\n",
        "        \n",
        "\n",
        "        # if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
        "        #     # 超参考： https://qiita.com/bowdbeg/items/71c62cf8ef891d164ecd#%E6%B3%A8%E6%84%8F%E7%82%B9\n",
        "        #     # unscale_ -> 勾配を直接操作する場合には，勾配の大きさを一度戻してから操作をします．例では勾配のクリッピング（勾配の最大値を決めておいて，超えたら小さくする）を挙げていますが，勾配が大きいままクリッピングすると間違った結果（おそらくすべてクリッピングされる）が出てしまいます．\n",
        "        #     scaler.unscale_(optimizer) # クリップ時に正しくできるように一度スケールを戻す\n",
        "        #     grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        #     scaler.step(optimizer) # パラメタの更新\n",
        "        #     scaler.update() # スケールの更新\n",
        "        #     optimizer.zero_grad()\n",
        "        #     global_step += 1\n",
        "        #     if CFG.batch_scheduler:\n",
        "        #         scheduler.step()\n",
        "\n",
        "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "            if CFG.batch_scheduler:\n",
        "                scheduler.step()\n",
        "\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad: {grad_norm:.4f} '\n",
        "                  'LR: {lr:.8f} '\n",
        "                  .format(epoch + 1, step, len(train_loader), remain = timeSince(start, float(step + 1)/len(train_loader)),\n",
        "                          loss = losses,\n",
        "                          grad_norm = grad_norm,\n",
        "                          lr = scheduler.get_lr()[0]\n",
        "                         )\n",
        "                 )\n",
        "    return losses.avg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97cdf99c",
      "metadata": {
        "id": "97cdf99c"
      },
      "source": [
        "# Valid function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c593bba1",
      "metadata": {
        "id": "c593bba1"
      },
      "outputs": [],
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "    for step, (inputs, labels) in enumerate(valid_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs)\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print('EVAL: [{0}/{1}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  .format(step, len(valid_loader),\n",
        "                          loss = losses,\n",
        "                          remain = timeSince(start, float(step + 1) / len(valid_loader))\n",
        "                         )\n",
        "                 )\n",
        "    return losses.avg, np.concatenate(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "415b6a15",
      "metadata": {
        "id": "415b6a15"
      },
      "source": [
        "# Logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9839f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df9839f9",
        "outputId": "571bd805-d4f5-495e-d6c9-c1813dc27212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OUTPUT_DIR: ./20221122-204903-deberta-v3-base/\n",
            "INFO:__main__:OUTPUT_DIR: ./20221122-204903-deberta-v3-base/\n"
          ]
        }
      ],
      "source": [
        "LOGGER = get_logger()\n",
        "LOGGER.info(f'OUTPUT_DIR: {CFG.OUTPUT_DIR}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59104d7e",
      "metadata": {
        "id": "59104d7e"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672fd430",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "b0d0263510864d2fbd0de47b2d980d79",
            "e8cf425228da4bd38d29b754e7ef782f",
            "262b110535ec46e3943ccd3f8ab740c1",
            "f0ed1eaf8a24470aaa267e63fee7b677",
            "4c70554620f240f1a571b5b881c5104d",
            "439a9bea298441218c50bfcda8a79404",
            "293b8aa1ac3d4c69997b6e04b71248c2",
            "7bf7dc8cea534808aa078dac35580e6c",
            "524df59c90f64d47ab4404b4284814d0",
            "41c97cb70bfa42419adad3e1fecb409f",
            "53aa12e301d241c6a584f0838bc3204c",
            "96534e14e146422186b36e758bac95c2",
            "218275b6c2db4bbb867f8da88063384c",
            "0ad8f7ab685c4044b7f951f3ca457d0d",
            "2ec634fb54a246809f1070ec7541f56b",
            "86e3e7d707724a4c9fa8e8475145dc40",
            "e20673ca67df4da19cf118956f871430",
            "64e2011322ce4128891284dd0266aadc",
            "072caa0408e347a49827eda8798aae95",
            "6c8015d529b34934af7099e14f4bfacb",
            "70e75470b17f46b9a3c758347f445d61",
            "45812dca1c4b4fd7b20c1aaa772fab77",
            "1858949da150465d85e1e728b424b727",
            "adc9f11a76534f7b9e782404a3391ce0",
            "96d9ee54c5014823831efd002cc564ff",
            "e8e25b0a58384baaa55eac9bda629219",
            "3aaba1da28754b1ca3ecde91528517e5",
            "66117190a25149678437bc74a42abf3c",
            "3b16e5b663e44c6cb81619ce8bee0a69",
            "a6c74f8d25b34b8fbe8135617ec29676",
            "7a0379af26344c8aba544ec49b753e16",
            "06abc8e28e0d481984df32a0a99182ff",
            "592a61a9c9db4b79aa105fb78d7bfb93",
            "c1526de4d45240f8b610fde11a72bb98",
            "b1741ddb23a944e5a02be4afba90aae3",
            "4d08622901ff42e690b0fa700a4f8e08",
            "dc64a9d4949542ceb1b77ab075669b18",
            "fcc9d7273bc446439c520025e69316dd",
            "44f1951306a745c7be72f1b3a8bbddf9",
            "4ec7c1bae928403aa1da5e2eb3b01497",
            "2ff59bf8c66749a599478ea12f493ff6",
            "fce09eb7df104082b9b614c019b58c0a",
            "a436db7162134ca3a5c2aa0f917a2d53",
            "bfd701991a6448d1a81a146bf3cebc04"
          ]
        },
        "id": "672fd430",
        "outputId": "dcbc1d15-9596-40d4-f3ba-03961080cca0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0d0263510864d2fbd0de47b2d980d79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96534e14e146422186b36e758bac95c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1858949da150465d85e1e728b424b727",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spm.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1526de4d45240f8b610fde11a72bb98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3911 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_len: 1428\n",
            "INFO:__main__:max_len: 1428\n"
          ]
        }
      ],
      "source": [
        "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
        "CFG.tokenizer.save_pretrained(CFG.OUTPUT_DIR + 'tokenizer')\n",
        "\n",
        "#max_len\n",
        "lengths = []\n",
        "tk0 = tqdm(CFG.df_train['full_text'].fillna('').values, total = len(CFG.df_train))\n",
        "for text in tk0:\n",
        "    length = len(CFG.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
        "    lengths.append(length)\n",
        "CFG.max_len = max(lengths) + 2\n",
        "LOGGER.info(f'max_len: {CFG.max_len}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdeaf267",
      "metadata": {
        "id": "cdeaf267"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff61a44",
      "metadata": {
        "id": "3ff61a44"
      },
      "outputs": [],
      "source": [
        "class FB3TrainDataset(Dataset):\n",
        "    def __init__(self, cfg, df):\n",
        "        self.cfg = cfg\n",
        "        self.texts = df['full_text'].values\n",
        "        self.labels = df[cfg.target_cols].values\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        inputs = prepare_input(self.cfg, self.texts[item])\n",
        "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
        "        return inputs, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a78dbf81",
      "metadata": {
        "id": "a78dbf81"
      },
      "source": [
        "# Model\n",
        "\n",
        "* Initializing module (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal) \n",
        "* Freeze lower layer when you use large model (v2-xlarge, funnnel, etc.)\n",
        "\n",
        "モジュールの初期化 (normal、xavier_uniform、xavier_normal、kaiming_uniform、kaiming_normal、orthogonal)  \n",
        "大きなモデル（v2-xlarge, funnnelなど）を使用する場合、下のレイヤーをフリーズさせる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f57c98c",
      "metadata": {
        "id": "0f57c98c"
      },
      "outputs": [],
      "source": [
        "class FB3Model(nn.Module):\n",
        "    def __init__(self, CFG, config_path = None, pretrained = False):\n",
        "        super().__init__()\n",
        "        self.CFG = CFG\n",
        "        if config_path is None:\n",
        "            self.config = AutoConfig.from_pretrained(CFG.model, output_hidden_states = True)\n",
        "            self.config.save_pretrained(CFG.OUTPUT_DIR + 'config')\n",
        "            self.config.hidden_dropout = 0.\n",
        "            self.config.hidden_dropout_prob = 0.\n",
        "            self.config.attention_dropout = 0.\n",
        "            self.config.attention_probs_dropout_prob = 0.\n",
        "        else:\n",
        "            self.config = torch.load(config_path)\n",
        "            \n",
        "        LOGGER.info(self.config)\n",
        "        \n",
        "        if pretrained:\n",
        "            self.model = AutoModel.from_pretrained(CFG.model, config=self.config)\n",
        "            self.model.save_pretrained(CFG.OUTPUT_DIR + 'model')\n",
        "        else:\n",
        "            #self.model = AutoModel(self.config)<- this is wrong\n",
        "            self.model = AutoModel.from_config(self.config)#<- this is correct\n",
        "\n",
        "\n",
        "        if self.CFG.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "            \n",
        "        if CFG.pooling == 'mean':\n",
        "            self.pool = MeanPooling()\n",
        "        elif CFG.pooling == 'max':\n",
        "            self.pool = MaxPooling()\n",
        "        elif CFG.pooling == 'min':\n",
        "            self.pool = MinPooling()\n",
        "        elif CFG.pooling == 'attention':\n",
        "            self.pool = AttentionPooling(self.config.hidden_size)\n",
        "        elif CFG.pooling == 'weightedlayer':\n",
        "            self.pool = WeightedLayerPooling(self.config.num_hidden_layers, layer_start = CFG.layer_start, layer_weights = None)        \n",
        "        \n",
        "        # self.config.hidden_size = 768\n",
        "        # self.CFG.n_targets(6)\n",
        "        # 768個の最終的なベクトル値から、６つの出力値を算出してほしい。\n",
        "        self.fc = nn.Linear(self.config.hidden_size, self.CFG.n_targets)\n",
        "        self._init_weights(self.fc)\n",
        "        \n",
        "        if 'deberta-v2-xxlarge' in CFG.model:\n",
        "            self.model.embeddings.requires_grad_(False)\n",
        "            self.model.encoder.layer[:24].requires_grad_(False)\n",
        "        if 'deberta-v2-xlarge' in CFG.model:\n",
        "            self.model.embeddings.requires_grad_(False)\n",
        "            self.model.encoder.layer[:12].requires_grad_(False)\n",
        "        if 'funnel-transformer-xlarge' in CFG.model:\n",
        "            self.model.embeddings.requires_grad_(False)\n",
        "            self.model.encoder.blocks[:1].requires_grad_(False)\n",
        "        if 'funnel-transformer-large' in CFG.model:\n",
        "            self.model.embeddings.requires_grad_(False)\n",
        "            self.model.encoder.blocks[:1].requires_grad_(False)\n",
        "        if 'deberta-large' in CFG.model:\n",
        "            self.model.embeddings.requires_grad_(False)\n",
        "            self.model.encoder.layer[:16].requires_grad_(False)\n",
        "        if 'deberta-xlarge' in CFG.model:\n",
        "            self.model.embeddings.requires_grad_(False)\n",
        "            self.model.encoder.layer[:36].requires_grad_(False)\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            if CFG.init_weight == 'normal':\n",
        "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
        "            elif CFG.init_weight == 'xavier_uniform':\n",
        "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'xavier_normal':\n",
        "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_uniform':\n",
        "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_normal':\n",
        "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'orthogonal':\n",
        "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
        "                \n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            if CFG.init_weight == 'normal':\n",
        "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
        "            elif CFG.init_weight == 'xavier_uniform':\n",
        "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'xavier_normal':\n",
        "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_uniform':\n",
        "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_normal':\n",
        "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'orthogonal':\n",
        "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
        "                \n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "    \n",
        "    def feature(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "\n",
        "        if CFG.pooling != 'weightedlayer':\n",
        "            # 最後の層の形(last_hidden_state)\n",
        "            # (Pdb) outputs[0].size()\n",
        "            # torch.Size([8, 676, 768])\n",
        "            last_hidden_states = outputs[0]\n",
        "            # last_hidden_states = outputs.last_hidden_state\n",
        "            feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
        "        else:\n",
        "            # 全ての層の形(hidden_states)\n",
        "            # (Pdb) outputs[1][0].shape\n",
        "            # torch.Size([8, 676, 768])\n",
        "            # (Pdb) outputs[1][1].shape\n",
        "            # torch.Size([8, 676, 768])\n",
        "            # (Pdb) outputs[1][2].shape\n",
        "            # torch.Size([8, 676, 768])\n",
        "\n",
        "            # all_layer_embeddings = outputs[1]\n",
        "            all_layer_embeddings = outputs.hidden_states\n",
        "            # all_hidden_states = torch.stack(all_layer_embeddings)\n",
        "\n",
        "            # feature = self.pool(all_layer_embeddings)\n",
        "            # Weighted pooling of last n layers.\n",
        "            feature = self.pool(all_layer_embeddings)[:, 0]  # Bx768\n",
        "            \n",
        "        return feature\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        feature = self.feature(inputs)\n",
        "        outout = self.fc(feature)\n",
        "        return outout"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37df1158",
      "metadata": {
        "id": "37df1158"
      },
      "source": [
        "# Train\n",
        "* Re-initializing upper layer (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal) \n",
        "* Layer-Wise Learning Rate Dacay (https://www.kaggle.com/code/rhtsingh/on-stability-of-few-sample-transformer-fine-tuning?scriptVersionId=67176591&cellId=29)\n",
        "* Loss function, SmoothL1 or RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd13fa6f",
      "metadata": {
        "id": "dd13fa6f"
      },
      "outputs": [],
      "source": [
        "def re_initializing_layer(model, config, layer_num):\n",
        "    # layer_num デフォルト=1(最後の１層だけreinitilizeする。)\n",
        "    for module in model.model.encoder.layer[-layer_num:].modules():\n",
        "        if isinstance(module, nn.Linear):\n",
        "            if CFG.init_weight == 'normal':\n",
        "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
        "            elif CFG.init_weight == 'xavier_uniform':\n",
        "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'xavier_normal':\n",
        "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_uniform':\n",
        "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_normal':\n",
        "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'orthogonal':\n",
        "                module.weight.data = nn.init.orthogonal_(module.weight.data) \n",
        "                \n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            if CFG.init_weight == 'normal':\n",
        "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
        "            elif CFG.init_weight == 'xavier_uniform':\n",
        "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'xavier_normal':\n",
        "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_uniform':\n",
        "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
        "            elif CFG.init_weight == 'kaiming_normal':\n",
        "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
        "            elif CFG.init_weight == 'orthogonal':\n",
        "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
        "                \n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "    return model   \n",
        "\n",
        "def train_loop(folds, fold):\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "    \n",
        "    train_folds = folds[folds['fold'] != fold].reset_index(drop = True)\n",
        "    valid_folds = folds[folds['fold'] == fold].reset_index(drop = True)\n",
        "    valid_labels = valid_folds[CFG.target_cols].values\n",
        "    \n",
        "    train_dataset = FB3TrainDataset(CFG, train_folds)\n",
        "    valid_dataset = FB3TrainDataset(CFG, valid_folds)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size = CFG.batch_size,\n",
        "                              shuffle = True, \n",
        "                              num_workers = CFG.num_workers,\n",
        "                              pin_memory = True, \n",
        "                              drop_last = True\n",
        "                             )\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size = CFG.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers,\n",
        "                              pin_memory=True, \n",
        "                              drop_last=False)\n",
        "\n",
        "\n",
        "    # from transformers import DataCollatorWithPadding\n",
        "    # train_loader = DataLoader(train_dataset,\n",
        "    #                           batch_size = CFG.batch_size,\n",
        "    #                           shuffle = True, \n",
        "    #                           num_workers = CFG.num_workers,\n",
        "    #                           collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding=\"longest\"),\n",
        "    #                           pin_memory = True, \n",
        "    #                           drop_last = True\n",
        "    #                          )\n",
        "    # valid_loader = DataLoader(valid_dataset,\n",
        "    #                         batch_size = CFG.batch_size * 2,\n",
        "    #                         shuffle=False,\n",
        "    #                         num_workers=CFG.num_workers,\n",
        "    #                         collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding=\"longest\"),\n",
        "    #                         pin_memory=True, \n",
        "    #                         drop_last=False)\n",
        "    \n",
        "\n",
        "\n",
        "    model = FB3Model(CFG, config_path = None, pretrained = CFG.use_pretrained)\n",
        "    # デフォルトTrue\n",
        "    if CFG.reinit:\n",
        "        model = re_initializing_layer(model, model.config, CFG.reinit_n) # デフォルト　　reinit_n=１\n",
        "        \n",
        "    #os.makedirs(CFG.OUTPUT_DIR + 'config/', exist_ok = True)\n",
        "    #torch.save(model.config, CFG.OUTPUT_DIR + 'config/config.pth')\n",
        "    model.to(CFG.device)\n",
        "    \n",
        "    def get_optimizer_params(model,\n",
        "                             encoder_lr,\n",
        "                             decoder_lr,\n",
        "                             weight_decay=0.0):\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr,\n",
        "             'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr,\n",
        "             'weight_decay': 0.0},\n",
        "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
        "             'lr': decoder_lr,\n",
        "             'weight_decay': 0.0}\n",
        "        ]\n",
        "        return optimizer_parameters\n",
        "    \n",
        "    #llrd\n",
        "    def get_optimizer_grouped_parameters(model, \n",
        "                                         layerwise_lr,\n",
        "                                         layerwise_weight_decay,\n",
        "                                         layerwise_lr_decay):\n",
        "        \n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        # initialize lr for task specific layer\n",
        "        optimizer_grouped_parameters = [{\"params\": [p for n, p in model.named_parameters() if \"model\" not in n],\n",
        "                                         \"weight_decay\": 0.0,\n",
        "                                         \"lr\": layerwise_lr,\n",
        "                                        },]\n",
        "        # initialize lrs for every layer\n",
        "        layers = [model.model.embeddings] + list(model.model.encoder.layer)\n",
        "        layers.reverse()\n",
        "        lr = layerwise_lr\n",
        "        for layer in layers:\n",
        "            optimizer_grouped_parameters += [{\"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                                              \"weight_decay\": layerwise_weight_decay,\n",
        "                                              \"lr\": lr,\n",
        "                                             },\n",
        "                                             {\"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                                              \"weight_decay\": 0.0,\n",
        "                                              \"lr\": lr,\n",
        "                                             },]\n",
        "            lr *= layerwise_lr_decay\n",
        "        return optimizer_grouped_parameters\n",
        "    \n",
        "    # デフォルトTrue\n",
        "    if CFG.llrd:\n",
        "        from transformers import AdamW\n",
        "        grouped_optimizer_params = get_optimizer_grouped_parameters(model, \n",
        "                                                                    CFG.layerwise_lr, \n",
        "                                                                    CFG.layerwise_weight_decay, \n",
        "                                                                    CFG.layerwise_lr_decay)\n",
        "        optimizer = AdamW(grouped_optimizer_params,\n",
        "                          lr = CFG.layerwise_lr,\n",
        "                          eps = CFG.layerwise_adam_epsilon,\n",
        "                          correct_bias = not CFG.layerwise_use_bertadam)\n",
        "    else:\n",
        "        from torch.optim import AdamW\n",
        "        optimizer_parameters = get_optimizer_params(model,\n",
        "                                                    encoder_lr=CFG.encoder_lr, \n",
        "                                                    decoder_lr=CFG.decoder_lr,\n",
        "                                                    weight_decay=CFG.weight_decay)\n",
        "        optimizer = AdamW(optimizer_parameters, \n",
        "                          lr=CFG.encoder_lr,\n",
        "                          eps=CFG.eps,\n",
        "                          betas=CFG.betas)\n",
        "    \n",
        "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "        if cfg.scheduler == 'linear':\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, \n",
        "                num_warmup_steps = cfg.num_warmup_steps, \n",
        "                num_training_steps = num_train_steps\n",
        "            )\n",
        "        elif cfg.scheduler == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, \n",
        "                num_warmup_steps = cfg.num_warmup_steps, \n",
        "                num_training_steps = num_train_steps,\n",
        "                num_cycles = cfg.num_cycles\n",
        "            )\n",
        "        return scheduler\n",
        "    \n",
        "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "    \n",
        "    # デフォルトSmoothL1\n",
        "    if CFG.loss_func == 'SmoothL1':\n",
        "        criterion = nn.SmoothL1Loss(reduction='mean')\n",
        "    elif CFG.loss_func == 'RMSE':\n",
        "        criterion = RMSELoss(reduction='mean')\n",
        "    \n",
        "    best_score = np.inf\n",
        "    best_train_loss = np.inf\n",
        "    best_val_loss = np.inf\n",
        "    \n",
        "    epoch_list = []\n",
        "    epoch_avg_loss_list = []\n",
        "    epoch_avg_val_loss_list = []\n",
        "    epoch_score_list = []\n",
        "    epoch_scores_list = []\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, CFG.device)\n",
        "        \n",
        "        # scoring\n",
        "        score, scores = get_score(valid_labels, predictions)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
        "        \n",
        "        epoch_list.append(epoch+1)\n",
        "        epoch_avg_loss_list.append(avg_loss)\n",
        "        epoch_avg_val_loss_list.append(avg_val_loss)\n",
        "        epoch_score_list.append(score)\n",
        "        epoch_scores_list.append(scores)\n",
        "        \n",
        "        if best_score > score:\n",
        "            best_score = score\n",
        "            best_train_loss = avg_loss\n",
        "            best_val_loss = avg_val_loss\n",
        "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "            \n",
        "        # デフォルトFalse(保存するのはベストスコアのモデルのみ)\n",
        "        if CFG.save_all_models:\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_epoch{epoch + 1}.pth\")\n",
        "\n",
        "    predictions = torch.load(CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
        "                             map_location = torch.device('cpu'))['predictions']\n",
        "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
        "    \n",
        "    df_epoch = pd.DataFrame({'epoch' : epoch_list,\n",
        "                             'MCRMSE' : epoch_score_list,\n",
        "                             'train_loss' : epoch_avg_loss_list, \n",
        "                             'val_loss' : epoch_avg_val_loss_list})\n",
        "    df_scores = pd.DataFrame(epoch_scores_list)\n",
        "    df_scores.columns = CFG.target_cols\n",
        "    \n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return best_train_loss, best_val_loss, valid_folds, pd.concat([df_epoch, df_scores], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1880b509",
      "metadata": {
        "id": "1880b509"
      },
      "source": [
        "# Run !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c85b19",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "787e8c3524e8480d8191f5677c7665bb",
            "e26aa784639d467db5b52de33838e7af",
            "dc377c6426d94b21b7e68161919b87f2",
            "7b310e168ae942fb94eae855723b371b",
            "311a383e1ff64a40ad926fc2b1611e6c",
            "3fd76c8051fd4fffaa22267911bf1bfe",
            "8976becc7af74ff3aee13bd76df0f567",
            "f370612454734f7a821d4de60311e2fe",
            "75cbcd33cc7b4012885174000f5d6800",
            "cb480d92bef14da490c43b8210a4404a",
            "f94b16f095bf4b8fb00f7fdbef6d143b"
          ]
        },
        "id": "68c85b19",
        "outputId": "72d6be44-2da5-4cb8-a90f-3e60ad5ebbeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "========== fold: 0 training ==========\n",
            "INFO:__main__:========== fold: 0 training ==========\n",
            "DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "INFO:__main__:DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "787e8c3524e8480d8191f5677c7665bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/354M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/366] Elapsed 0m 6s (remain 39m 52s) Loss: 2.8944(2.8944) Grad: inf LR: 0.00005000 \n",
            "Epoch: [1][20/366] Elapsed 1m 20s (remain 22m 6s) Loss: 0.2239(0.9478) Grad: 249337.7031 LR: 0.00004998 \n",
            "Epoch: [1][40/366] Elapsed 2m 34s (remain 20m 20s) Loss: 0.0932(0.5955) Grad: 93935.9375 LR: 0.00004994 \n",
            "Epoch: [1][60/366] Elapsed 3m 35s (remain 17m 58s) Loss: 0.1148(0.4565) Grad: 547389.8750 LR: 0.00004986 \n",
            "Epoch: [1][80/366] Elapsed 4m 48s (remain 16m 54s) Loss: 0.1707(0.3855) Grad: 408735.4062 LR: 0.00004976 \n",
            "Epoch: [1][100/366] Elapsed 6m 9s (remain 16m 9s) Loss: 0.1322(0.3432) Grad: 121231.5469 LR: 0.00004963 \n",
            "Epoch: [1][120/366] Elapsed 7m 29s (remain 15m 10s) Loss: 0.1614(0.3113) Grad: 262559.1562 LR: 0.00004946 \n",
            "Epoch: [1][140/366] Elapsed 8m 49s (remain 14m 4s) Loss: 0.1220(0.2869) Grad: 155246.5625 LR: 0.00004927 \n",
            "Epoch: [1][160/366] Elapsed 10m 0s (remain 12m 45s) Loss: 0.1385(0.2662) Grad: 108641.7188 LR: 0.00004905 \n",
            "Epoch: [1][180/366] Elapsed 11m 3s (remain 11m 17s) Loss: 0.1356(0.2544) Grad: 118132.8281 LR: 0.00004881 \n",
            "Epoch: [1][200/366] Elapsed 12m 22s (remain 10m 9s) Loss: 0.1474(0.2439) Grad: 110608.1406 LR: 0.00004853 \n",
            "Epoch: [1][220/366] Elapsed 13m 50s (remain 9m 5s) Loss: 0.0960(0.2335) Grad: 126675.9844 LR: 0.00004823 \n",
            "Epoch: [1][240/366] Elapsed 14m 56s (remain 7m 45s) Loss: 0.1385(0.2252) Grad: 285795.6875 LR: 0.00004790 \n",
            "Epoch: [1][260/366] Elapsed 16m 15s (remain 6m 32s) Loss: 0.0941(0.2166) Grad: 74768.6953 LR: 0.00004754 \n",
            "Epoch: [1][280/366] Elapsed 17m 28s (remain 5m 17s) Loss: 0.0980(0.2098) Grad: 88431.8828 LR: 0.00004716 \n",
            "Epoch: [1][300/366] Elapsed 18m 54s (remain 4m 4s) Loss: 0.1379(0.2047) Grad: 144704.9219 LR: 0.00004675 \n",
            "Epoch: [1][320/366] Elapsed 20m 15s (remain 2m 50s) Loss: 0.1593(0.1989) Grad: 223857.3281 LR: 0.00004631 \n",
            "Epoch: [1][340/366] Elapsed 21m 31s (remain 1m 34s) Loss: 0.1002(0.1946) Grad: 94431.8438 LR: 0.00004585 \n",
            "Epoch: [1][360/366] Elapsed 22m 45s (remain 0m 18s) Loss: 0.1365(0.1906) Grad: 263136.6250 LR: 0.00004537 \n",
            "Epoch: [1][365/366] Elapsed 23m 3s (remain 0m 0s) Loss: 0.1285(0.1896) Grad: 146209.4375 LR: 0.00004524 \n",
            "EVAL: [0/62] Elapsed 0m 2s (remain 2m 7s) Loss: 0.0841(0.0841) \n",
            "EVAL: [20/62] Elapsed 0m 48s (remain 1m 34s) Loss: 0.0966(0.1132) \n",
            "EVAL: [40/62] Elapsed 1m 40s (remain 0m 51s) Loss: 0.1045(0.1150) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.1896  avg_val_loss: 0.1172  time: 1528s\n",
            "INFO:__main__:Epoch 1 - avg_train_loss: 0.1896  avg_val_loss: 0.1172  time: 1528s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVAL: [60/62] Elapsed 2m 24s (remain 0m 2s) Loss: 0.1088(0.1170) \n",
            "EVAL: [61/62] Elapsed 2m 24s (remain 0m 0s) Loss: 0.2141(0.1172) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Score: 0.4845  Scores: [0.5166058369669654, 0.4643924032283523, 0.4221675087030496, 0.5019327485499676, 0.4786412464326382, 0.5233151747341349]\n",
            "INFO:__main__:Epoch 1 - Score: 0.4845  Scores: [0.5166058369669654, 0.4643924032283523, 0.4221675087030496, 0.5019327485499676, 0.4786412464326382, 0.5233151747341349]\n",
            "Epoch 1 - Save Best Score: 0.4845 Model\n",
            "INFO:__main__:Epoch 1 - Save Best Score: 0.4845 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/366] Elapsed 0m 3s (remain 19m 50s) Loss: 0.0535(0.0535) Grad: 89878.7734 LR: 0.00004522 \n",
            "Epoch: [2][20/366] Elapsed 1m 27s (remain 24m 4s) Loss: 0.0597(0.1107) Grad: 122228.9609 LR: 0.00004470 \n",
            "Epoch: [2][40/366] Elapsed 2m 47s (remain 22m 9s) Loss: 0.0870(0.1089) Grad: 125756.2656 LR: 0.00004416 \n",
            "Epoch: [2][60/366] Elapsed 4m 3s (remain 20m 17s) Loss: 0.1625(0.1089) Grad: 105039.7969 LR: 0.00004360 \n",
            "Epoch: [2][80/366] Elapsed 5m 16s (remain 18m 34s) Loss: 0.1667(0.1118) Grad: 357041.3750 LR: 0.00004302 \n",
            "Epoch: [2][100/366] Elapsed 6m 35s (remain 17m 18s) Loss: 0.1083(0.1101) Grad: 262105.9219 LR: 0.00004241 \n",
            "Epoch: [2][120/366] Elapsed 7m 50s (remain 15m 53s) Loss: 0.0869(0.1133) Grad: 93185.2891 LR: 0.00004179 \n",
            "Epoch: [2][140/366] Elapsed 9m 0s (remain 14m 22s) Loss: 0.1520(0.1172) Grad: 172722.0625 LR: 0.00004114 \n",
            "Epoch: [2][160/366] Elapsed 10m 22s (remain 13m 13s) Loss: 0.0637(0.1158) Grad: 95371.0547 LR: 0.00004048 \n",
            "Epoch: [2][180/366] Elapsed 11m 43s (remain 11m 58s) Loss: 0.1414(0.1158) Grad: 124908.2422 LR: 0.00003979 \n",
            "Epoch: [2][200/366] Elapsed 13m 14s (remain 10m 52s) Loss: 0.1128(0.1166) Grad: 155964.9062 LR: 0.00003910 \n",
            "Epoch: [2][220/366] Elapsed 14m 17s (remain 9m 22s) Loss: 0.1140(0.1164) Grad: 100844.5234 LR: 0.00003838 \n",
            "Epoch: [2][240/366] Elapsed 15m 30s (remain 8m 2s) Loss: 0.1124(0.1163) Grad: 103703.1875 LR: 0.00003765 \n",
            "Epoch: [2][260/366] Elapsed 16m 51s (remain 6m 46s) Loss: 0.1014(0.1164) Grad: 57836.5352 LR: 0.00003690 \n",
            "Epoch: [2][280/366] Elapsed 18m 10s (remain 5m 30s) Loss: 0.0922(0.1175) Grad: 38223.7656 LR: 0.00003614 \n",
            "Epoch: [2][300/366] Elapsed 19m 20s (remain 4m 10s) Loss: 0.1638(0.1182) Grad: 154420.8281 LR: 0.00003537 \n",
            "Epoch: [2][320/366] Elapsed 20m 44s (remain 2m 54s) Loss: 0.0972(0.1178) Grad: 354249.0938 LR: 0.00003458 \n",
            "Epoch: [2][340/366] Elapsed 21m 56s (remain 1m 36s) Loss: 0.0891(0.1180) Grad: 75764.7891 LR: 0.00003378 \n",
            "Epoch: [2][360/366] Elapsed 23m 7s (remain 0m 19s) Loss: 0.1285(0.1179) Grad: 70006.3672 LR: 0.00003298 \n",
            "Epoch: [2][365/366] Elapsed 23m 29s (remain 0m 0s) Loss: 0.0938(0.1177) Grad: 186399.8281 LR: 0.00003277 \n",
            "EVAL: [0/62] Elapsed 0m 2s (remain 2m 9s) Loss: 0.0960(0.0960) \n",
            "EVAL: [20/62] Elapsed 0m 48s (remain 1m 34s) Loss: 0.0954(0.1197) \n",
            "EVAL: [40/62] Elapsed 1m 39s (remain 0m 51s) Loss: 0.0806(0.1191) \n",
            "EVAL: [60/62] Elapsed 2m 23s (remain 0m 2s) Loss: 0.1034(0.1201) \n",
            "EVAL: [61/62] Elapsed 2m 23s (remain 0m 0s) Loss: 0.0750(0.1200) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.1177  avg_val_loss: 0.1200  time: 1553s\n",
            "INFO:__main__:Epoch 2 - avg_train_loss: 0.1177  avg_val_loss: 0.1200  time: 1553s\n",
            "Epoch 2 - Score: 0.4884  Scores: [0.5551479098167819, 0.44559391485008876, 0.4123401648584682, 0.4591865688830185, 0.5881148866559549, 0.4702808024778197]\n",
            "INFO:__main__:Epoch 2 - Score: 0.4884  Scores: [0.5551479098167819, 0.44559391485008876, 0.4123401648584682, 0.4591865688830185, 0.5881148866559549, 0.4702808024778197]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/366] Elapsed 0m 4s (remain 27m 35s) Loss: 0.1298(0.1298) Grad: 473856.1562 LR: 0.00003273 \n",
            "Epoch: [3][20/366] Elapsed 1m 17s (remain 21m 9s) Loss: 0.1386(0.1166) Grad: 168306.8438 LR: 0.00003191 \n",
            "Epoch: [3][40/366] Elapsed 2m 29s (remain 19m 48s) Loss: 0.0891(0.1039) Grad: 153166.2031 LR: 0.00003109 \n",
            "Epoch: [3][60/366] Elapsed 4m 3s (remain 20m 15s) Loss: 0.0733(0.1002) Grad: 191705.9219 LR: 0.00003025 \n",
            "Epoch: [3][80/366] Elapsed 5m 6s (remain 17m 57s) Loss: 0.1222(0.1004) Grad: 173571.3125 LR: 0.00002941 \n",
            "Epoch: [3][100/366] Elapsed 6m 18s (remain 16m 33s) Loss: 0.1193(0.0987) Grad: 143217.2344 LR: 0.00002857 \n",
            "Epoch: [3][120/366] Elapsed 7m 39s (remain 15m 30s) Loss: 0.1281(0.0994) Grad: 156708.7031 LR: 0.00002772 \n",
            "Epoch: [3][140/366] Elapsed 8m 58s (remain 14m 19s) Loss: 0.0757(0.0995) Grad: 245494.6719 LR: 0.00002686 \n",
            "Epoch: [3][160/366] Elapsed 10m 13s (remain 13m 0s) Loss: 0.1274(0.0992) Grad: 354919.5312 LR: 0.00002601 \n",
            "Epoch: [3][180/366] Elapsed 11m 28s (remain 11m 43s) Loss: 0.1028(0.0989) Grad: 144443.5312 LR: 0.00002515 \n",
            "Epoch: [3][200/366] Elapsed 12m 43s (remain 10m 26s) Loss: 0.1224(0.0978) Grad: 100759.5312 LR: 0.00002429 \n",
            "Epoch: [3][220/366] Elapsed 14m 2s (remain 9m 13s) Loss: 0.0866(0.0972) Grad: 352042.4375 LR: 0.00002344 \n",
            "Epoch: [3][240/366] Elapsed 15m 17s (remain 7m 56s) Loss: 0.1565(0.0988) Grad: 631052.5000 LR: 0.00002258 \n",
            "Epoch: [3][260/366] Elapsed 16m 45s (remain 6m 44s) Loss: 0.0936(0.0993) Grad: 135431.0938 LR: 0.00002173 \n",
            "Epoch: [3][280/366] Elapsed 18m 0s (remain 5m 26s) Loss: 0.0815(0.0984) Grad: 132518.7188 LR: 0.00002088 \n",
            "Epoch: [3][300/366] Elapsed 18m 57s (remain 4m 5s) Loss: 0.1091(0.0983) Grad: 229946.7344 LR: 0.00002004 \n",
            "Epoch: [3][320/366] Elapsed 20m 25s (remain 2m 51s) Loss: 0.0728(0.0980) Grad: 166447.9844 LR: 0.00001920 \n",
            "Epoch: [3][340/366] Elapsed 21m 46s (remain 1m 35s) Loss: 0.0949(0.0976) Grad: 211543.0000 LR: 0.00001837 \n",
            "Epoch: [3][360/366] Elapsed 22m 50s (remain 0m 18s) Loss: 0.0742(0.0971) Grad: 135674.9688 LR: 0.00001755 \n",
            "Epoch: [3][365/366] Elapsed 23m 2s (remain 0m 0s) Loss: 0.1124(0.0971) Grad: 258160.5938 LR: 0.00001735 \n",
            "EVAL: [0/62] Elapsed 0m 2s (remain 2m 8s) Loss: 0.0837(0.0837) \n",
            "EVAL: [20/62] Elapsed 0m 48s (remain 1m 34s) Loss: 0.0860(0.1132) \n",
            "EVAL: [40/62] Elapsed 1m 39s (remain 0m 51s) Loss: 0.0832(0.1122) \n",
            "EVAL: [60/62] Elapsed 2m 23s (remain 0m 2s) Loss: 0.0888(0.1134) \n",
            "EVAL: [61/62] Elapsed 2m 23s (remain 0m 0s) Loss: 0.0784(0.1134) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0971  avg_val_loss: 0.1134  time: 1527s\n",
            "INFO:__main__:Epoch 3 - avg_train_loss: 0.0971  avg_val_loss: 0.1134  time: 1527s\n",
            "Epoch 3 - Score: 0.4766  Scores: [0.5236215967657519, 0.45737021070458284, 0.42002328181671944, 0.47401213774423545, 0.5227576321165105, 0.4615153513264214]\n",
            "INFO:__main__:Epoch 3 - Score: 0.4766  Scores: [0.5236215967657519, 0.45737021070458284, 0.42002328181671944, 0.47401213774423545, 0.5227576321165105, 0.4615153513264214]\n",
            "Epoch 3 - Save Best Score: 0.4766 Model\n",
            "INFO:__main__:Epoch 3 - Save Best Score: 0.4766 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [4][0/366] Elapsed 0m 2s (remain 17m 6s) Loss: 0.0981(0.0981) Grad: 218291.7500 LR: 0.00001731 \n",
            "Epoch: [4][20/366] Elapsed 1m 21s (remain 22m 17s) Loss: 0.1067(0.0947) Grad: 215753.1719 LR: 0.00001650 \n",
            "Epoch: [4][40/366] Elapsed 2m 40s (remain 21m 15s) Loss: 0.1038(0.0926) Grad: 179845.6250 LR: 0.00001570 \n",
            "Epoch: [4][60/366] Elapsed 4m 2s (remain 20m 12s) Loss: 0.0773(0.0915) Grad: 77028.5859 LR: 0.00001491 \n",
            "Epoch: [4][80/366] Elapsed 5m 29s (remain 19m 18s) Loss: 0.0723(0.0934) Grad: 96933.2656 LR: 0.00001413 \n",
            "Epoch: [4][100/366] Elapsed 6m 50s (remain 17m 58s) Loss: 0.0836(0.0913) Grad: 481355.9375 LR: 0.00001336 \n",
            "Epoch: [4][120/366] Elapsed 8m 6s (remain 16m 24s) Loss: 0.1066(0.0907) Grad: 170421.5781 LR: 0.00001261 \n",
            "Epoch: [4][140/366] Elapsed 9m 2s (remain 14m 26s) Loss: 0.0588(0.0897) Grad: 103703.2031 LR: 0.00001187 \n",
            "Epoch: [4][160/366] Elapsed 10m 15s (remain 13m 3s) Loss: 0.0996(0.0887) Grad: 142369.1406 LR: 0.00001115 \n",
            "Epoch: [4][180/366] Elapsed 11m 25s (remain 11m 40s) Loss: 0.0549(0.0887) Grad: 131380.2500 LR: 0.00001045 \n",
            "Epoch: [4][200/366] Elapsed 12m 45s (remain 10m 28s) Loss: 0.1028(0.0883) Grad: 152475.0312 LR: 0.00000976 \n",
            "Epoch: [4][220/366] Elapsed 14m 5s (remain 9m 14s) Loss: 0.1100(0.0880) Grad: 272454.6875 LR: 0.00000909 \n",
            "Epoch: [4][240/366] Elapsed 15m 11s (remain 7m 52s) Loss: 0.0796(0.0876) Grad: 221915.0312 LR: 0.00000844 \n",
            "Epoch: [4][260/366] Elapsed 16m 15s (remain 6m 32s) Loss: 0.1220(0.0878) Grad: 137758.3438 LR: 0.00000781 \n",
            "Epoch: [4][280/366] Elapsed 17m 28s (remain 5m 17s) Loss: 0.0727(0.0876) Grad: 123410.0469 LR: 0.00000719 \n",
            "Epoch: [4][300/366] Elapsed 18m 50s (remain 4m 4s) Loss: 0.0793(0.0873) Grad: 621928.2500 LR: 0.00000660 \n",
            "Epoch: [4][320/366] Elapsed 20m 12s (remain 2m 49s) Loss: 0.1003(0.0867) Grad: 166458.5938 LR: 0.00000603 \n",
            "Epoch: [4][340/366] Elapsed 21m 21s (remain 1m 33s) Loss: 0.0539(0.0863) Grad: 103365.8984 LR: 0.00000549 \n",
            "Epoch: [4][360/366] Elapsed 22m 47s (remain 0m 18s) Loss: 0.0642(0.0865) Grad: 95154.2188 LR: 0.00000496 \n",
            "Epoch: [4][365/366] Elapsed 23m 15s (remain 0m 0s) Loss: 0.1036(0.0865) Grad: 160224.6406 LR: 0.00000484 \n",
            "EVAL: [0/62] Elapsed 0m 2s (remain 2m 11s) Loss: 0.0671(0.0671) \n",
            "EVAL: [20/62] Elapsed 0m 48s (remain 1m 34s) Loss: 0.0819(0.0994) \n",
            "EVAL: [40/62] Elapsed 1m 40s (remain 0m 51s) Loss: 0.0851(0.1009) \n",
            "EVAL: [60/62] Elapsed 2m 24s (remain 0m 2s) Loss: 0.0892(0.1021) \n",
            "EVAL: [61/62] Elapsed 2m 24s (remain 0m 0s) Loss: 0.1377(0.1021) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0865  avg_val_loss: 0.1021  time: 1540s\n",
            "INFO:__main__:Epoch 4 - avg_train_loss: 0.0865  avg_val_loss: 0.1021  time: 1540s\n",
            "Epoch 4 - Score: 0.4523  Scores: [0.4804440439867704, 0.4428827378834765, 0.41334224121718405, 0.45569633639957297, 0.4740067926901743, 0.44754813188902104]\n",
            "INFO:__main__:Epoch 4 - Score: 0.4523  Scores: [0.4804440439867704, 0.4428827378834765, 0.41334224121718405, 0.45569633639957297, 0.4740067926901743, 0.44754813188902104]\n",
            "Epoch 4 - Save Best Score: 0.4523 Model\n",
            "INFO:__main__:Epoch 4 - Save Best Score: 0.4523 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [5][0/366] Elapsed 0m 2s (remain 14m 20s) Loss: 0.0629(0.0629) Grad: 164027.2031 LR: 0.00000481 \n",
            "Epoch: [5][20/366] Elapsed 1m 30s (remain 24m 38s) Loss: 0.0985(0.0813) Grad: 120286.6328 LR: 0.00000432 \n",
            "Epoch: [5][40/366] Elapsed 2m 49s (remain 22m 24s) Loss: 0.0590(0.0815) Grad: 172239.5469 LR: 0.00000385 \n",
            "Epoch: [5][60/366] Elapsed 4m 18s (remain 21m 32s) Loss: 0.0763(0.0816) Grad: 176728.3281 LR: 0.00000340 \n",
            "Epoch: [5][80/366] Elapsed 5m 43s (remain 20m 9s) Loss: 0.0702(0.0834) Grad: 76157.9844 LR: 0.00000298 \n",
            "Epoch: [5][100/366] Elapsed 7m 15s (remain 19m 1s) Loss: 0.0898(0.0833) Grad: 155166.7500 LR: 0.00000259 \n",
            "Epoch: [5][120/366] Elapsed 8m 29s (remain 17m 10s) Loss: 0.0892(0.0830) Grad: 119514.1953 LR: 0.00000222 \n",
            "Epoch: [5][140/366] Elapsed 9m 47s (remain 15m 37s) Loss: 0.0531(0.0822) Grad: 158665.0938 LR: 0.00000188 \n",
            "Epoch: [5][160/366] Elapsed 11m 16s (remain 14m 20s) Loss: 0.0711(0.0816) Grad: 442521.4375 LR: 0.00000157 \n",
            "Epoch: [5][180/366] Elapsed 12m 30s (remain 12m 46s) Loss: 0.0563(0.0813) Grad: 71081.4062 LR: 0.00000129 \n",
            "Epoch: [5][200/366] Elapsed 13m 36s (remain 11m 10s) Loss: 0.0566(0.0803) Grad: 118979.0859 LR: 0.00000103 \n",
            "Epoch: [5][220/366] Elapsed 14m 49s (remain 9m 43s) Loss: 0.0512(0.0800) Grad: 123715.4688 LR: 0.00000080 \n",
            "Epoch: [5][240/366] Elapsed 15m 59s (remain 8m 17s) Loss: 0.1165(0.0800) Grad: 213502.7344 LR: 0.00000060 \n",
            "Epoch: [5][260/366] Elapsed 17m 9s (remain 6m 54s) Loss: 0.0661(0.0800) Grad: 90432.6797 LR: 0.00000043 \n",
            "Epoch: [5][280/366] Elapsed 18m 17s (remain 5m 31s) Loss: 0.0582(0.0799) Grad: 154624.2031 LR: 0.00000028 \n",
            "Epoch: [5][300/366] Elapsed 19m 21s (remain 4m 10s) Loss: 0.0664(0.0791) Grad: 123762.8047 LR: 0.00000017 \n",
            "Epoch: [5][320/366] Elapsed 20m 28s (remain 2m 52s) Loss: 0.0921(0.0792) Grad: 222290.4844 LR: 0.00000008 \n",
            "Epoch: [5][340/366] Elapsed 21m 36s (remain 1m 35s) Loss: 0.0793(0.0792) Grad: 90786.9062 LR: 0.00000003 \n",
            "Epoch: [5][360/366] Elapsed 23m 0s (remain 0m 19s) Loss: 0.0356(0.0794) Grad: 81924.9219 LR: 0.00000000 \n",
            "Epoch: [5][365/366] Elapsed 23m 17s (remain 0m 0s) Loss: 0.0788(0.0794) Grad: 172982.6562 LR: 0.00000000 \n",
            "EVAL: [0/62] Elapsed 0m 2s (remain 2m 12s) Loss: 0.0679(0.0679) \n",
            "EVAL: [20/62] Elapsed 0m 48s (remain 1m 34s) Loss: 0.0782(0.0989) \n",
            "EVAL: [40/62] Elapsed 1m 40s (remain 0m 51s) Loss: 0.0852(0.1004) \n",
            "EVAL: [60/62] Elapsed 2m 23s (remain 0m 2s) Loss: 0.0900(0.1016) \n",
            "EVAL: [61/62] Elapsed 2m 23s (remain 0m 0s) Loss: 0.1330(0.1017) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0794  avg_val_loss: 0.1017  time: 1542s\n",
            "INFO:__main__:Epoch 5 - avg_train_loss: 0.0794  avg_val_loss: 0.1017  time: 1542s\n",
            "Epoch 5 - Score: 0.4513  Scores: [0.478605129778871, 0.4432413051128967, 0.4142878033050902, 0.4537354641661687, 0.47274798742125274, 0.4454029484819989]\n",
            "INFO:__main__:Epoch 5 - Score: 0.4513  Scores: [0.478605129778871, 0.4432413051128967, 0.4142878033050902, 0.4537354641661687, 0.47274798742125274, 0.4454029484819989]\n",
            "Epoch 5 - Save Best Score: 0.4513 Model\n",
            "INFO:__main__:Epoch 5 - Save Best Score: 0.4513 Model\n",
            "========== fold: 0 result ==========\n",
            "INFO:__main__:========== fold: 0 result ==========\n",
            "Score: 0.4513  Scores: [0.478605129778871, 0.4432413051128967, 0.4142878033050902, 0.4537354641661687, 0.47274798742125274, 0.4454029484819989]\n",
            "INFO:__main__:Score: 0.4513  Scores: [0.478605129778871, 0.4432413051128967, 0.4142878033050902, 0.4537354641661687, 0.47274798742125274, 0.4454029484819989]\n",
            "========== fold: 1 training ==========\n",
            "INFO:__main__:========== fold: 1 training ==========\n",
            "DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "INFO:__main__:DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/366] Elapsed 0m 2s (remain 17m 45s) Loss: 3.0144(3.0144) Grad: inf LR: 0.00005000 \n",
            "Epoch: [1][20/366] Elapsed 1m 25s (remain 23m 19s) Loss: 0.3365(0.9843) Grad: 185801.0000 LR: 0.00004998 \n",
            "Epoch: [1][40/366] Elapsed 2m 39s (remain 21m 7s) Loss: 0.1528(0.6014) Grad: 285145.6562 LR: 0.00004994 \n",
            "Epoch: [1][60/366] Elapsed 3m 44s (remain 18m 44s) Loss: 0.1358(0.4598) Grad: 55339.6797 LR: 0.00004986 \n",
            "Epoch: [1][80/366] Elapsed 4m 57s (remain 17m 26s) Loss: 0.1268(0.3846) Grad: 199278.3125 LR: 0.00004976 \n",
            "Epoch: [1][100/366] Elapsed 6m 10s (remain 16m 11s) Loss: 0.0910(0.3387) Grad: 61622.6367 LR: 0.00004963 \n",
            "Epoch: [1][120/366] Elapsed 7m 33s (remain 15m 18s) Loss: 0.1627(0.3044) Grad: 122441.0469 LR: 0.00004946 \n",
            "Epoch: [1][140/366] Elapsed 9m 6s (remain 14m 32s) Loss: 0.1362(0.2819) Grad: 149974.4219 LR: 0.00004927 \n",
            "Epoch: [1][160/366] Elapsed 10m 24s (remain 13m 15s) Loss: 0.1073(0.2638) Grad: 97639.4453 LR: 0.00004905 \n",
            "Epoch: [1][180/366] Elapsed 11m 50s (remain 12m 6s) Loss: 0.1009(0.2498) Grad: 142800.8438 LR: 0.00004881 \n",
            "Epoch: [1][200/366] Elapsed 13m 2s (remain 10m 42s) Loss: 0.1790(0.2408) Grad: 99067.7188 LR: 0.00004853 \n",
            "Epoch: [1][220/366] Elapsed 14m 10s (remain 9m 18s) Loss: 0.1327(0.2318) Grad: 109012.7656 LR: 0.00004823 \n",
            "Epoch: [1][240/366] Elapsed 15m 30s (remain 8m 2s) Loss: 0.2017(0.2252) Grad: 136706.7344 LR: 0.00004790 \n",
            "Epoch: [1][260/366] Elapsed 16m 51s (remain 6m 46s) Loss: 0.0919(0.2186) Grad: 81430.9062 LR: 0.00004754 \n",
            "Epoch: [1][280/366] Elapsed 18m 12s (remain 5m 30s) Loss: 0.0903(0.2116) Grad: 69654.3281 LR: 0.00004716 \n",
            "Epoch: [1][300/366] Elapsed 19m 25s (remain 4m 11s) Loss: 0.2140(0.2060) Grad: 125584.2266 LR: 0.00004675 \n",
            "Epoch: [1][320/366] Elapsed 20m 40s (remain 2m 53s) Loss: 0.1019(0.2004) Grad: 76825.7734 LR: 0.00004631 \n",
            "Epoch: [1][340/366] Elapsed 21m 58s (remain 1m 36s) Loss: 0.0571(0.1953) Grad: 40593.6680 LR: 0.00004585 \n",
            "Epoch: [1][360/366] Elapsed 23m 4s (remain 0m 19s) Loss: 0.0787(0.1918) Grad: 51032.6523 LR: 0.00004537 \n",
            "Epoch: [1][365/366] Elapsed 23m 21s (remain 0m 0s) Loss: 0.1206(0.1907) Grad: 103169.9531 LR: 0.00004524 \n",
            "EVAL: [0/62] Elapsed 0m 1s (remain 1m 54s) Loss: 0.0944(0.0944) \n",
            "EVAL: [20/62] Elapsed 0m 48s (remain 1m 34s) Loss: 0.1137(0.1176) \n",
            "EVAL: [40/62] Elapsed 1m 33s (remain 0m 48s) Loss: 0.0900(0.1161) \n",
            "EVAL: [60/62] Elapsed 2m 25s (remain 0m 2s) Loss: 0.0932(0.1144) \n",
            "EVAL: [61/62] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0529(0.1144) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.1907  avg_val_loss: 0.1144  time: 1548s\n",
            "INFO:__main__:Epoch 1 - avg_train_loss: 0.1907  avg_val_loss: 0.1144  time: 1548s\n",
            "Epoch 1 - Score: 0.4800  Scores: [0.5071949401773158, 0.4811181092273413, 0.45229030172197005, 0.4860021176527844, 0.4861682682588802, 0.4672638134697356]\n",
            "INFO:__main__:Epoch 1 - Score: 0.4800  Scores: [0.5071949401773158, 0.4811181092273413, 0.45229030172197005, 0.4860021176527844, 0.4861682682588802, 0.4672638134697356]\n",
            "Epoch 1 - Save Best Score: 0.4800 Model\n",
            "INFO:__main__:Epoch 1 - Save Best Score: 0.4800 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/366] Elapsed 0m 4s (remain 24m 44s) Loss: 0.0980(0.0980) Grad: 208969.1562 LR: 0.00004522 \n",
            "Epoch: [2][20/366] Elapsed 1m 34s (remain 25m 54s) Loss: 0.0787(0.1062) Grad: 163212.0625 LR: 0.00004470 \n",
            "Epoch: [2][40/366] Elapsed 2m 49s (remain 22m 21s) Loss: 0.0963(0.1069) Grad: 71933.9609 LR: 0.00004416 \n",
            "Epoch: [2][60/366] Elapsed 3m 59s (remain 19m 59s) Loss: 0.1583(0.1106) Grad: 563730.3750 LR: 0.00004360 \n",
            "Epoch: [2][80/366] Elapsed 5m 3s (remain 17m 46s) Loss: 0.0729(0.1104) Grad: 75943.2500 LR: 0.00004302 \n",
            "Epoch: [2][100/366] Elapsed 6m 20s (remain 16m 38s) Loss: 0.1014(0.1083) Grad: 76378.5391 LR: 0.00004241 \n",
            "Epoch: [2][120/366] Elapsed 7m 32s (remain 15m 15s) Loss: 0.0838(0.1117) Grad: 65169.1133 LR: 0.00004179 \n",
            "Epoch: [2][140/366] Elapsed 9m 4s (remain 14m 28s) Loss: 0.1130(0.1134) Grad: 86601.5391 LR: 0.00004114 \n",
            "Epoch: [2][160/366] Elapsed 10m 13s (remain 13m 0s) Loss: 0.1102(0.1132) Grad: 128392.6875 LR: 0.00004048 \n",
            "Epoch: [2][180/366] Elapsed 11m 34s (remain 11m 49s) Loss: 0.1461(0.1148) Grad: 182838.7656 LR: 0.00003979 \n",
            "Epoch: [2][200/366] Elapsed 13m 6s (remain 10m 45s) Loss: 0.1166(0.1151) Grad: 216980.5938 LR: 0.00003910 \n",
            "Epoch: [2][220/366] Elapsed 14m 11s (remain 9m 18s) Loss: 0.1198(0.1154) Grad: 93160.5547 LR: 0.00003838 \n",
            "Epoch: [2][240/366] Elapsed 15m 17s (remain 7m 55s) Loss: 0.1281(0.1156) Grad: 59472.0078 LR: 0.00003765 \n",
            "Epoch: [2][260/366] Elapsed 16m 18s (remain 6m 33s) Loss: 0.1295(0.1155) Grad: 105415.4375 LR: 0.00003690 \n",
            "Epoch: [2][280/366] Elapsed 17m 58s (remain 5m 26s) Loss: 0.1329(0.1209) Grad: 158267.1250 LR: 0.00003614 \n",
            "Epoch: [2][300/366] Elapsed 19m 11s (remain 4m 8s) Loss: 0.0743(0.1202) Grad: 81982.9453 LR: 0.00003537 \n",
            "Epoch: [2][320/366] Elapsed 20m 36s (remain 2m 53s) Loss: 0.1023(0.1188) Grad: 87221.7109 LR: 0.00003458 \n",
            "Epoch: [2][340/366] Elapsed 21m 49s (remain 1m 36s) Loss: 0.1433(0.1185) Grad: 108755.9922 LR: 0.00003378 \n",
            "Epoch: [2][360/366] Elapsed 22m 59s (remain 0m 19s) Loss: 0.0610(0.1185) Grad: 68415.8516 LR: 0.00003298 \n",
            "Epoch: [2][365/366] Elapsed 23m 12s (remain 0m 0s) Loss: 0.1107(0.1183) Grad: 153372.9844 LR: 0.00003277 \n",
            "EVAL: [0/62] Elapsed 0m 1s (remain 1m 50s) Loss: 0.1089(0.1089) \n",
            "EVAL: [20/62] Elapsed 0m 47s (remain 1m 33s) Loss: 0.1316(0.1267) \n",
            "EVAL: [40/62] Elapsed 1m 33s (remain 0m 47s) Loss: 0.1094(0.1246) \n",
            "EVAL: [60/62] Elapsed 2m 24s (remain 0m 2s) Loss: 0.1057(0.1236) \n",
            "EVAL: [61/62] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0532(0.1235) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.1183  avg_val_loss: 0.1235  time: 1538s\n",
            "INFO:__main__:Epoch 2 - avg_train_loss: 0.1183  avg_val_loss: 0.1235  time: 1538s\n",
            "Epoch 2 - Score: 0.4988  Scores: [0.514069458750838, 0.5092017358255654, 0.5324132410090103, 0.47297533590449725, 0.5045669337032987, 0.45954814410973494]\n",
            "INFO:__main__:Epoch 2 - Score: 0.4988  Scores: [0.514069458750838, 0.5092017358255654, 0.5324132410090103, 0.47297533590449725, 0.5045669337032987, 0.45954814410973494]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/366] Elapsed 0m 2s (remain 15m 38s) Loss: 0.0751(0.0751) Grad: 133694.1875 LR: 0.00003273 \n",
            "Epoch: [3][20/366] Elapsed 1m 19s (remain 21m 52s) Loss: 0.1176(0.1205) Grad: 94722.2422 LR: 0.00003191 \n",
            "Epoch: [3][40/366] Elapsed 2m 53s (remain 22m 51s) Loss: 0.0985(0.1134) Grad: 165260.6562 LR: 0.00003109 \n",
            "Epoch: [3][60/366] Elapsed 4m 15s (remain 21m 17s) Loss: 0.1378(0.1131) Grad: 108298.5938 LR: 0.00003025 \n",
            "Epoch: [3][80/366] Elapsed 5m 26s (remain 19m 9s) Loss: 0.1384(0.1117) Grad: 71327.9062 LR: 0.00002941 \n",
            "Epoch: [3][100/366] Elapsed 6m 36s (remain 17m 20s) Loss: 0.0624(0.1082) Grad: 63909.2734 LR: 0.00002857 \n",
            "Epoch: [3][120/366] Elapsed 7m 37s (remain 15m 26s) Loss: 0.0828(0.1059) Grad: 65382.1875 LR: 0.00002772 \n",
            "Epoch: [3][140/366] Elapsed 8m 58s (remain 14m 18s) Loss: 0.1371(0.1060) Grad: 76874.1094 LR: 0.00002686 \n",
            "Epoch: [3][160/366] Elapsed 10m 4s (remain 12m 49s) Loss: 0.1499(0.1061) Grad: 190443.8125 LR: 0.00002601 \n",
            "Epoch: [3][180/366] Elapsed 11m 13s (remain 11m 28s) Loss: 0.0914(0.1062) Grad: 113476.7266 LR: 0.00002515 \n",
            "Epoch: [3][200/366] Elapsed 12m 29s (remain 10m 15s) Loss: 0.1101(0.1055) Grad: 352760.8438 LR: 0.00002429 \n",
            "Epoch: [3][220/366] Elapsed 13m 33s (remain 8m 53s) Loss: 0.0727(0.1049) Grad: 99359.5703 LR: 0.00002344 \n",
            "Epoch: [3][240/366] Elapsed 14m 50s (remain 7m 42s) Loss: 0.0775(0.1038) Grad: 45143.0508 LR: 0.00002258 \n",
            "Epoch: [3][260/366] Elapsed 16m 11s (remain 6m 30s) Loss: 0.0711(0.1036) Grad: 55259.2656 LR: 0.00002173 \n",
            "Epoch: [3][280/366] Elapsed 17m 30s (remain 5m 17s) Loss: 0.1055(0.1030) Grad: 113913.9609 LR: 0.00002088 \n",
            "Epoch: [3][300/366] Elapsed 19m 3s (remain 4m 6s) Loss: 0.0555(0.1028) Grad: 59665.6641 LR: 0.00002004 \n",
            "Epoch: [3][320/366] Elapsed 20m 15s (remain 2m 50s) Loss: 0.0723(0.1020) Grad: 66060.4219 LR: 0.00001920 \n",
            "Epoch: [3][340/366] Elapsed 21m 34s (remain 1m 34s) Loss: 0.1298(0.1016) Grad: 137322.3125 LR: 0.00001837 \n",
            "Epoch: [3][360/366] Elapsed 22m 45s (remain 0m 18s) Loss: 0.0799(0.1004) Grad: 56367.8828 LR: 0.00001755 \n",
            "Epoch: [3][365/366] Elapsed 23m 5s (remain 0m 0s) Loss: 0.0922(0.1001) Grad: 73700.0234 LR: 0.00001735 \n",
            "EVAL: [0/62] Elapsed 0m 2s (remain 2m 5s) Loss: 0.1080(0.1080) \n",
            "EVAL: [20/62] Elapsed 0m 47s (remain 1m 33s) Loss: 0.1097(0.1166) \n",
            "EVAL: [40/62] Elapsed 1m 33s (remain 0m 47s) Loss: 0.0909(0.1123) \n",
            "EVAL: [60/62] Elapsed 2m 25s (remain 0m 2s) Loss: 0.0986(0.1112) \n",
            "EVAL: [61/62] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0707(0.1112) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.1001  avg_val_loss: 0.1112  time: 1531s\n",
            "INFO:__main__:Epoch 3 - avg_train_loss: 0.1001  avg_val_loss: 0.1112  time: 1531s\n",
            "Epoch 3 - Score: 0.4732  Scores: [0.49693205552107683, 0.4652737224703387, 0.470461032583116, 0.46431392980354824, 0.48018119375182794, 0.4623198132293221]\n",
            "INFO:__main__:Epoch 3 - Score: 0.4732  Scores: [0.49693205552107683, 0.4652737224703387, 0.470461032583116, 0.46431392980354824, 0.48018119375182794, 0.4623198132293221]\n",
            "Epoch 3 - Save Best Score: 0.4732 Model\n",
            "INFO:__main__:Epoch 3 - Save Best Score: 0.4732 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [4][0/366] Elapsed 0m 3s (remain 22m 8s) Loss: 0.0641(0.0641) Grad: 135789.6562 LR: 0.00001731 \n",
            "Epoch: [4][20/366] Elapsed 1m 11s (remain 19m 36s) Loss: 0.0664(0.0787) Grad: 119659.0469 LR: 0.00001650 \n",
            "Epoch: [4][40/366] Elapsed 2m 41s (remain 21m 20s) Loss: 0.0810(0.0852) Grad: 124668.6875 LR: 0.00001570 \n",
            "Epoch: [4][60/366] Elapsed 3m 48s (remain 19m 2s) Loss: 0.0867(0.0828) Grad: 138502.9375 LR: 0.00001491 \n",
            "Epoch: [4][80/366] Elapsed 5m 5s (remain 17m 54s) Loss: 0.0870(0.0840) Grad: 127236.0938 LR: 0.00001413 \n",
            "Epoch: [4][100/366] Elapsed 6m 25s (remain 16m 51s) Loss: 0.0760(0.0848) Grad: 141602.1094 LR: 0.00001336 \n",
            "Epoch: [4][120/366] Elapsed 7m 36s (remain 15m 23s) Loss: 0.0756(0.0836) Grad: 184555.5625 LR: 0.00001261 \n",
            "Epoch: [4][140/366] Elapsed 8m 42s (remain 13m 53s) Loss: 0.1201(0.0828) Grad: 141509.7188 LR: 0.00001187 \n",
            "Epoch: [4][160/366] Elapsed 10m 6s (remain 12m 52s) Loss: 0.0847(0.0825) Grad: 248834.7031 LR: 0.00001115 \n",
            "Epoch: [4][180/366] Elapsed 11m 15s (remain 11m 30s) Loss: 0.0672(0.0823) Grad: 83965.3828 LR: 0.00001045 \n",
            "Epoch: [4][200/366] Elapsed 12m 27s (remain 10m 13s) Loss: 0.0798(0.0821) Grad: 134976.6562 LR: 0.00000976 \n",
            "Epoch: [4][220/366] Elapsed 13m 59s (remain 9m 10s) Loss: 0.1022(0.0816) Grad: 260296.6719 LR: 0.00000909 \n",
            "Epoch: [4][240/366] Elapsed 15m 14s (remain 7m 54s) Loss: 0.0866(0.0815) Grad: 628984.5000 LR: 0.00000844 \n",
            "Epoch: [4][260/366] Elapsed 16m 32s (remain 6m 39s) Loss: 0.0836(0.0807) Grad: 218839.0938 LR: 0.00000781 \n",
            "Epoch: [4][280/366] Elapsed 18m 0s (remain 5m 26s) Loss: 0.0587(0.0808) Grad: 136533.8281 LR: 0.00000719 \n",
            "Epoch: [4][300/366] Elapsed 19m 3s (remain 4m 6s) Loss: 0.0788(0.0808) Grad: 186259.5781 LR: 0.00000660 \n",
            "Epoch: [4][320/366] Elapsed 20m 8s (remain 2m 49s) Loss: 0.0649(0.0810) Grad: 102180.7891 LR: 0.00000603 \n",
            "Epoch: [4][340/366] Elapsed 21m 29s (remain 1m 34s) Loss: 0.0748(0.0815) Grad: 91452.5000 LR: 0.00000549 \n",
            "Epoch: [4][360/366] Elapsed 22m 39s (remain 0m 18s) Loss: 0.0511(0.0812) Grad: 96898.8750 LR: 0.00000496 \n",
            "Epoch: [4][365/366] Elapsed 23m 7s (remain 0m 0s) Loss: 0.1164(0.0813) Grad: 490409.2812 LR: 0.00000484 \n",
            "EVAL: [0/62] Elapsed 0m 1s (remain 1m 57s) Loss: 0.1046(0.1046) \n",
            "EVAL: [20/62] Elapsed 0m 47s (remain 1m 33s) Loss: 0.1201(0.1209) \n",
            "EVAL: [40/62] Elapsed 1m 33s (remain 0m 47s) Loss: 0.0891(0.1140) \n",
            "EVAL: [60/62] Elapsed 2m 25s (remain 0m 2s) Loss: 0.0827(0.1105) \n",
            "EVAL: [61/62] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0332(0.1104) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0813  avg_val_loss: 0.1104  time: 1534s\n",
            "INFO:__main__:Epoch 4 - avg_train_loss: 0.0813  avg_val_loss: 0.1104  time: 1534s\n",
            "Epoch 4 - Score: 0.4711  Scores: [0.4898605888070261, 0.45945409683095806, 0.43427605942612435, 0.47893015093798125, 0.5037806714674193, 0.4605301970038488]\n",
            "INFO:__main__:Epoch 4 - Score: 0.4711  Scores: [0.4898605888070261, 0.45945409683095806, 0.43427605942612435, 0.47893015093798125, 0.5037806714674193, 0.4605301970038488]\n",
            "Epoch 4 - Save Best Score: 0.4711 Model\n",
            "INFO:__main__:Epoch 4 - Save Best Score: 0.4711 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [5][0/366] Elapsed 0m 5s (remain 31m 51s) Loss: 0.0709(0.0709) Grad: 201213.4375 LR: 0.00000481 \n",
            "Epoch: [5][20/366] Elapsed 1m 24s (remain 23m 5s) Loss: 0.0795(0.0861) Grad: 320364.0625 LR: 0.00000432 \n",
            "Epoch: [5][40/366] Elapsed 2m 50s (remain 22m 31s) Loss: 0.0716(0.0772) Grad: 95317.4766 LR: 0.00000385 \n",
            "Epoch: [5][60/366] Elapsed 4m 5s (remain 20m 28s) Loss: 0.0561(0.0775) Grad: 155738.2500 LR: 0.00000340 \n",
            "Epoch: [5][80/366] Elapsed 5m 13s (remain 18m 24s) Loss: 0.0697(0.0778) Grad: 195366.8125 LR: 0.00000298 \n",
            "Epoch: [5][100/366] Elapsed 6m 36s (remain 17m 20s) Loss: 0.0884(0.0767) Grad: 237675.0312 LR: 0.00000259 \n",
            "Epoch: [5][120/366] Elapsed 7m 40s (remain 15m 33s) Loss: 0.0847(0.0774) Grad: 309678.9062 LR: 0.00000222 \n",
            "Epoch: [5][140/366] Elapsed 9m 9s (remain 14m 36s) Loss: 0.0787(0.0767) Grad: 202877.7344 LR: 0.00000188 \n",
            "Epoch: [5][160/366] Elapsed 10m 23s (remain 13m 13s) Loss: 0.0608(0.0766) Grad: 99023.7344 LR: 0.00000157 \n",
            "Epoch: [5][180/366] Elapsed 11m 45s (remain 12m 0s) Loss: 0.0689(0.0762) Grad: 123640.5312 LR: 0.00000129 \n",
            "Epoch: [5][200/366] Elapsed 12m 52s (remain 10m 34s) Loss: 0.0924(0.0761) Grad: 249151.3594 LR: 0.00000103 \n",
            "Epoch: [5][220/366] Elapsed 14m 15s (remain 9m 21s) Loss: 0.0839(0.0763) Grad: 197756.1406 LR: 0.00000080 \n",
            "Epoch: [5][240/366] Elapsed 15m 32s (remain 8m 3s) Loss: 0.0556(0.0766) Grad: 141342.4219 LR: 0.00000060 \n",
            "Epoch: [5][260/366] Elapsed 16m 53s (remain 6m 47s) Loss: 0.1100(0.0763) Grad: 351077.5625 LR: 0.00000043 \n",
            "Epoch: [5][280/366] Elapsed 18m 13s (remain 5m 30s) Loss: 0.0873(0.0760) Grad: 105208.8828 LR: 0.00000028 \n",
            "Epoch: [5][300/366] Elapsed 19m 28s (remain 4m 12s) Loss: 0.0755(0.0759) Grad: 101589.7969 LR: 0.00000017 \n",
            "Epoch: [5][320/366] Elapsed 20m 41s (remain 2m 54s) Loss: 0.0714(0.0760) Grad: 116402.3750 LR: 0.00000008 \n",
            "Epoch: [5][340/366] Elapsed 21m 54s (remain 1m 36s) Loss: 0.0727(0.0757) Grad: 88305.1328 LR: 0.00000003 \n",
            "Epoch: [5][360/366] Elapsed 23m 19s (remain 0m 19s) Loss: 0.0578(0.0754) Grad: 128545.0391 LR: 0.00000000 \n",
            "Epoch: [5][365/366] Elapsed 23m 37s (remain 0m 0s) Loss: 0.0660(0.0753) Grad: 209507.3438 LR: 0.00000000 \n",
            "EVAL: [0/62] Elapsed 0m 1s (remain 1m 57s) Loss: 0.1029(0.1029) \n",
            "EVAL: [20/62] Elapsed 0m 48s (remain 1m 33s) Loss: 0.1000(0.1105) \n",
            "EVAL: [40/62] Elapsed 1m 33s (remain 0m 47s) Loss: 0.0882(0.1065) \n",
            "EVAL: [60/62] Elapsed 2m 25s (remain 0m 2s) Loss: 0.0840(0.1054) \n",
            "EVAL: [61/62] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0570(0.1054) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0753  avg_val_loss: 0.1054  time: 1564s\n",
            "INFO:__main__:Epoch 5 - avg_train_loss: 0.0753  avg_val_loss: 0.1054  time: 1564s\n",
            "Epoch 5 - Score: 0.4600  Scores: [0.4924053434884276, 0.4525067301809601, 0.42169166092680954, 0.4594370044127613, 0.47763720778275015, 0.45650501268204186]\n",
            "INFO:__main__:Epoch 5 - Score: 0.4600  Scores: [0.4924053434884276, 0.4525067301809601, 0.42169166092680954, 0.4594370044127613, 0.47763720778275015, 0.45650501268204186]\n",
            "Epoch 5 - Save Best Score: 0.4600 Model\n",
            "INFO:__main__:Epoch 5 - Save Best Score: 0.4600 Model\n",
            "========== fold: 1 result ==========\n",
            "INFO:__main__:========== fold: 1 result ==========\n",
            "Score: 0.4600  Scores: [0.4924053434884276, 0.4525067301809601, 0.42169166092680954, 0.4594370044127613, 0.47763720778275015, 0.45650501268204186]\n",
            "INFO:__main__:Score: 0.4600  Scores: [0.4924053434884276, 0.4525067301809601, 0.42169166092680954, 0.4594370044127613, 0.47763720778275015, 0.45650501268204186]\n",
            "========== fold: 2 training ==========\n",
            "INFO:__main__:========== fold: 2 training ==========\n",
            "DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "INFO:__main__:DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/366] Elapsed 0m 2s (remain 13m 17s) Loss: 3.3264(3.3264) Grad: inf LR: 0.00005000 \n",
            "Epoch: [1][20/366] Elapsed 1m 27s (remain 23m 54s) Loss: 0.2955(1.1140) Grad: 210630.2188 LR: 0.00004998 \n",
            "Epoch: [1][40/366] Elapsed 2m 35s (remain 20m 35s) Loss: 0.1568(0.6758) Grad: 137934.5781 LR: 0.00004994 \n",
            "Epoch: [1][60/366] Elapsed 3m 56s (remain 19m 42s) Loss: 0.2667(0.5151) Grad: 386234.5938 LR: 0.00004986 \n",
            "Epoch: [1][80/366] Elapsed 5m 20s (remain 18m 49s) Loss: 0.1141(0.4256) Grad: 86722.5469 LR: 0.00004976 \n",
            "Epoch: [1][100/366] Elapsed 6m 41s (remain 17m 34s) Loss: 0.1059(0.3671) Grad: 71064.0625 LR: 0.00004963 \n",
            "Epoch: [1][120/366] Elapsed 7m 59s (remain 16m 11s) Loss: 0.1889(0.3317) Grad: 195252.7500 LR: 0.00004946 \n",
            "Epoch: [1][140/366] Elapsed 9m 14s (remain 14m 45s) Loss: 0.1290(0.3028) Grad: 135393.5000 LR: 0.00004927 \n",
            "Epoch: [1][160/366] Elapsed 10m 28s (remain 13m 20s) Loss: 0.1288(0.2857) Grad: 56181.2500 LR: 0.00004905 \n",
            "Epoch: [1][180/366] Elapsed 11m 46s (remain 12m 2s) Loss: 0.1374(0.2682) Grad: 125204.6016 LR: 0.00004881 \n",
            "Epoch: [1][200/366] Elapsed 13m 17s (remain 10m 54s) Loss: 0.1702(0.2568) Grad: 110156.4219 LR: 0.00004853 \n",
            "Epoch: [1][220/366] Elapsed 14m 27s (remain 9m 28s) Loss: 0.1149(0.2473) Grad: 125399.6875 LR: 0.00004823 \n",
            "Epoch: [1][240/366] Elapsed 15m 43s (remain 8m 9s) Loss: 0.0994(0.2358) Grad: 100578.9375 LR: 0.00004790 \n",
            "Epoch: [1][260/366] Elapsed 17m 2s (remain 6m 51s) Loss: 0.1195(0.2282) Grad: 96961.3750 LR: 0.00004754 \n",
            "Epoch: [1][280/366] Elapsed 18m 33s (remain 5m 36s) Loss: 0.1100(0.2207) Grad: 125973.2344 LR: 0.00004716 \n",
            "Epoch: [1][300/366] Elapsed 19m 54s (remain 4m 17s) Loss: 0.0928(0.2139) Grad: 84445.7188 LR: 0.00004675 \n",
            "Epoch: [1][320/366] Elapsed 20m 59s (remain 2m 56s) Loss: 0.1261(0.2088) Grad: 143253.9688 LR: 0.00004631 \n",
            "Epoch: [1][340/366] Elapsed 22m 23s (remain 1m 38s) Loss: 0.0955(0.2049) Grad: 193898.8438 LR: 0.00004585 \n",
            "Epoch: [1][360/366] Elapsed 23m 46s (remain 0m 19s) Loss: 0.2695(0.2011) Grad: 621542.0625 LR: 0.00004537 \n",
            "Epoch: [1][365/366] Elapsed 24m 0s (remain 0m 0s) Loss: 0.0773(0.2001) Grad: 68336.6797 LR: 0.00004524 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 4m 3s) Loss: 0.1325(0.1325) \n",
            "EVAL: [20/62] Elapsed 0m 46s (remain 1m 31s) Loss: 0.0809(0.1193) \n",
            "EVAL: [40/62] Elapsed 1m 26s (remain 0m 44s) Loss: 0.0854(0.1173) \n",
            "EVAL: [60/62] Elapsed 2m 10s (remain 0m 2s) Loss: 0.1013(0.1165) \n",
            "EVAL: [61/62] Elapsed 2m 10s (remain 0m 0s) Loss: 0.1212(0.1166) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.2001  avg_val_loss: 0.1166  time: 1572s\n",
            "INFO:__main__:Epoch 1 - avg_train_loss: 0.2001  avg_val_loss: 0.1166  time: 1572s\n",
            "Epoch 1 - Score: 0.4848  Scores: [0.5152904201488296, 0.46611265518128675, 0.4443902438256496, 0.5229307574607618, 0.5008080979509052, 0.45917298014277824]\n",
            "INFO:__main__:Epoch 1 - Score: 0.4848  Scores: [0.5152904201488296, 0.46611265518128675, 0.4443902438256496, 0.5229307574607618, 0.5008080979509052, 0.45917298014277824]\n",
            "Epoch 1 - Save Best Score: 0.4848 Model\n",
            "INFO:__main__:Epoch 1 - Save Best Score: 0.4848 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/366] Elapsed 0m 3s (remain 18m 59s) Loss: 0.0942(0.0942) Grad: 122904.6250 LR: 0.00004522 \n",
            "Epoch: [2][20/366] Elapsed 1m 22s (remain 22m 30s) Loss: 0.1048(0.1083) Grad: 265847.8438 LR: 0.00004470 \n",
            "Epoch: [2][40/366] Elapsed 2m 42s (remain 21m 31s) Loss: 0.0774(0.1060) Grad: 405075.7812 LR: 0.00004416 \n",
            "Epoch: [2][60/366] Elapsed 3m 52s (remain 19m 23s) Loss: 0.1517(0.1094) Grad: 149277.9688 LR: 0.00004360 \n",
            "Epoch: [2][80/366] Elapsed 5m 2s (remain 17m 45s) Loss: 0.1511(0.1060) Grad: 214213.8438 LR: 0.00004302 \n",
            "Epoch: [2][100/366] Elapsed 6m 25s (remain 16m 50s) Loss: 0.0992(0.1085) Grad: 284894.3438 LR: 0.00004241 \n",
            "Epoch: [2][120/366] Elapsed 7m 47s (remain 15m 47s) Loss: 0.1271(0.1112) Grad: 255820.6562 LR: 0.00004179 \n",
            "Epoch: [2][140/366] Elapsed 9m 3s (remain 14m 26s) Loss: 0.1304(0.1105) Grad: 215418.7500 LR: 0.00004114 \n",
            "Epoch: [2][160/366] Elapsed 10m 30s (remain 13m 23s) Loss: 0.0714(0.1097) Grad: 271245.9688 LR: 0.00004048 \n",
            "Epoch: [2][180/366] Elapsed 11m 48s (remain 12m 3s) Loss: 0.1184(0.1085) Grad: 291862.5000 LR: 0.00003979 \n",
            "Epoch: [2][200/366] Elapsed 13m 5s (remain 10m 44s) Loss: 0.0580(0.1070) Grad: 91574.2734 LR: 0.00003910 \n",
            "Epoch: [2][220/366] Elapsed 14m 16s (remain 9m 21s) Loss: 0.1127(0.1076) Grad: 141087.2812 LR: 0.00003838 \n",
            "Epoch: [2][240/366] Elapsed 15m 24s (remain 7m 59s) Loss: 0.0593(0.1072) Grad: 111434.3281 LR: 0.00003765 \n",
            "Epoch: [2][260/366] Elapsed 16m 57s (remain 6m 49s) Loss: 0.0870(0.1076) Grad: 147399.2500 LR: 0.00003690 \n",
            "Epoch: [2][280/366] Elapsed 18m 5s (remain 5m 28s) Loss: 0.1262(0.1070) Grad: 196207.7500 LR: 0.00003614 \n",
            "Epoch: [2][300/366] Elapsed 19m 26s (remain 4m 11s) Loss: 0.0892(0.1068) Grad: 168531.5156 LR: 0.00003537 \n",
            "Epoch: [2][320/366] Elapsed 20m 47s (remain 2m 54s) Loss: 0.1484(0.1077) Grad: 214057.9844 LR: 0.00003458 \n",
            "Epoch: [2][340/366] Elapsed 22m 10s (remain 1m 37s) Loss: 0.2009(0.1075) Grad: 896121.0000 LR: 0.00003378 \n",
            "Epoch: [2][360/366] Elapsed 23m 33s (remain 0m 19s) Loss: 0.1358(0.1075) Grad: 515364.4062 LR: 0.00003298 \n",
            "Epoch: [2][365/366] Elapsed 23m 50s (remain 0m 0s) Loss: 0.0743(0.1076) Grad: 113351.6562 LR: 0.00003277 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 3m 56s) Loss: 0.1396(0.1396) \n",
            "EVAL: [20/62] Elapsed 0m 46s (remain 1m 30s) Loss: 0.0824(0.1230) \n",
            "EVAL: [40/62] Elapsed 1m 25s (remain 0m 44s) Loss: 0.0984(0.1190) \n",
            "EVAL: [60/62] Elapsed 2m 9s (remain 0m 2s) Loss: 0.1028(0.1196) \n",
            "EVAL: [61/62] Elapsed 2m 9s (remain 0m 0s) Loss: 0.0720(0.1195) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.1076  avg_val_loss: 0.1195  time: 1561s\n",
            "INFO:__main__:Epoch 2 - avg_train_loss: 0.1076  avg_val_loss: 0.1195  time: 1561s\n",
            "Epoch 2 - Score: 0.4904  Scores: [0.556471607938989, 0.4756338544546303, 0.4766730958994695, 0.4816646073855688, 0.4862050310946466, 0.4658883286168824]\n",
            "INFO:__main__:Epoch 2 - Score: 0.4904  Scores: [0.556471607938989, 0.4756338544546303, 0.4766730958994695, 0.4816646073855688, 0.4862050310946466, 0.4658883286168824]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/366] Elapsed 0m 6s (remain 37m 52s) Loss: 0.0963(0.0963) Grad: 210465.0156 LR: 0.00003273 \n",
            "Epoch: [3][20/366] Elapsed 1m 35s (remain 26m 12s) Loss: 0.1336(0.0992) Grad: 278199.3125 LR: 0.00003191 \n",
            "Epoch: [3][40/366] Elapsed 2m 42s (remain 21m 25s) Loss: 0.1050(0.1013) Grad: 109436.9531 LR: 0.00003109 \n",
            "Epoch: [3][60/366] Elapsed 3m 56s (remain 19m 41s) Loss: 0.0705(0.0994) Grad: 119330.7891 LR: 0.00003025 \n",
            "Epoch: [3][80/366] Elapsed 4m 56s (remain 17m 22s) Loss: 0.1387(0.1004) Grad: 314932.3125 LR: 0.00002941 \n",
            "Epoch: [3][100/366] Elapsed 6m 15s (remain 16m 24s) Loss: 0.0837(0.0998) Grad: 184886.8125 LR: 0.00002857 \n",
            "Epoch: [3][120/366] Elapsed 7m 33s (remain 15m 18s) Loss: 0.0697(0.0990) Grad: 125896.0547 LR: 0.00002772 \n",
            "Epoch: [3][140/366] Elapsed 8m 47s (remain 14m 0s) Loss: 0.0893(0.0980) Grad: 159468.1875 LR: 0.00002686 \n",
            "Epoch: [3][160/366] Elapsed 10m 14s (remain 13m 2s) Loss: 0.0728(0.0983) Grad: 200902.9062 LR: 0.00002601 \n",
            "Epoch: [3][180/366] Elapsed 11m 38s (remain 11m 53s) Loss: 0.0968(0.0985) Grad: 200732.6094 LR: 0.00002515 \n",
            "Epoch: [3][200/366] Elapsed 12m 58s (remain 10m 38s) Loss: 0.0906(0.0986) Grad: 125387.2734 LR: 0.00002429 \n",
            "Epoch: [3][220/366] Elapsed 14m 22s (remain 9m 25s) Loss: 0.0695(0.0987) Grad: 150269.7188 LR: 0.00002344 \n",
            "Epoch: [3][240/366] Elapsed 15m 34s (remain 8m 4s) Loss: 0.1035(0.0995) Grad: 151551.6562 LR: 0.00002258 \n",
            "Epoch: [3][260/366] Elapsed 16m 34s (remain 6m 40s) Loss: 0.0855(0.0984) Grad: 163474.7656 LR: 0.00002173 \n",
            "Epoch: [3][280/366] Elapsed 17m 42s (remain 5m 21s) Loss: 0.1109(0.0976) Grad: 186395.3438 LR: 0.00002088 \n",
            "Epoch: [3][300/366] Elapsed 19m 15s (remain 4m 9s) Loss: 0.0806(0.0980) Grad: 179568.0938 LR: 0.00002004 \n",
            "Epoch: [3][320/366] Elapsed 20m 44s (remain 2m 54s) Loss: 0.0494(0.0970) Grad: 100174.9375 LR: 0.00001920 \n",
            "Epoch: [3][340/366] Elapsed 22m 4s (remain 1m 37s) Loss: 0.0994(0.0973) Grad: 142054.6094 LR: 0.00001837 \n",
            "Epoch: [3][360/366] Elapsed 23m 27s (remain 0m 19s) Loss: 0.0656(0.0970) Grad: 129906.9375 LR: 0.00001755 \n",
            "Epoch: [3][365/366] Elapsed 23m 56s (remain 0m 0s) Loss: 0.0775(0.0969) Grad: 165507.9062 LR: 0.00001735 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 4m 1s) Loss: 0.1253(0.1253) \n",
            "EVAL: [20/62] Elapsed 0m 46s (remain 1m 30s) Loss: 0.0853(0.1068) \n",
            "EVAL: [40/62] Elapsed 1m 26s (remain 0m 44s) Loss: 0.1026(0.1071) \n",
            "EVAL: [60/62] Elapsed 2m 9s (remain 0m 2s) Loss: 0.0971(0.1076) \n",
            "EVAL: [61/62] Elapsed 2m 9s (remain 0m 0s) Loss: 0.0886(0.1076) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0969  avg_val_loss: 0.1076  time: 1567s\n",
            "INFO:__main__:Epoch 3 - avg_train_loss: 0.0969  avg_val_loss: 0.1076  time: 1567s\n",
            "Epoch 3 - Score: 0.4652  Scores: [0.4792339506118323, 0.4647498334440563, 0.42285066267951565, 0.4834022000329994, 0.4836375531406769, 0.45723362261359013]\n",
            "INFO:__main__:Epoch 3 - Score: 0.4652  Scores: [0.4792339506118323, 0.4647498334440563, 0.42285066267951565, 0.4834022000329994, 0.4836375531406769, 0.45723362261359013]\n",
            "Epoch 3 - Save Best Score: 0.4652 Model\n",
            "INFO:__main__:Epoch 3 - Save Best Score: 0.4652 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [4][0/366] Elapsed 0m 2s (remain 13m 24s) Loss: 0.0810(0.0810) Grad: 144488.3750 LR: 0.00001731 \n",
            "Epoch: [4][20/366] Elapsed 1m 21s (remain 22m 18s) Loss: 0.0956(0.0847) Grad: 113018.5938 LR: 0.00001650 \n",
            "Epoch: [4][40/366] Elapsed 2m 39s (remain 21m 4s) Loss: 0.0662(0.0873) Grad: 102146.5469 LR: 0.00001570 \n",
            "Epoch: [4][60/366] Elapsed 3m 57s (remain 19m 45s) Loss: 0.0671(0.0866) Grad: 90265.5859 LR: 0.00001491 \n",
            "Epoch: [4][80/366] Elapsed 5m 17s (remain 18m 38s) Loss: 0.1418(0.0868) Grad: 284374.5312 LR: 0.00001413 \n",
            "Epoch: [4][100/366] Elapsed 6m 43s (remain 17m 39s) Loss: 0.1171(0.0876) Grad: 317769.2812 LR: 0.00001336 \n",
            "Epoch: [4][120/366] Elapsed 8m 1s (remain 16m 14s) Loss: 0.0990(0.0885) Grad: 125862.7031 LR: 0.00001261 \n",
            "Epoch: [4][140/366] Elapsed 9m 22s (remain 14m 57s) Loss: 0.0727(0.0877) Grad: 106305.3125 LR: 0.00001187 \n",
            "Epoch: [4][160/366] Elapsed 10m 34s (remain 13m 27s) Loss: 0.0720(0.0865) Grad: 367891.1250 LR: 0.00001115 \n",
            "Epoch: [4][180/366] Elapsed 12m 2s (remain 12m 18s) Loss: 0.0863(0.0868) Grad: 69479.8047 LR: 0.00001045 \n",
            "Epoch: [4][200/366] Elapsed 13m 22s (remain 10m 58s) Loss: 0.0603(0.0865) Grad: 184011.4844 LR: 0.00000976 \n",
            "Epoch: [4][220/366] Elapsed 14m 39s (remain 9m 37s) Loss: 0.1052(0.0859) Grad: 180179.1875 LR: 0.00000909 \n",
            "Epoch: [4][240/366] Elapsed 15m 55s (remain 8m 15s) Loss: 0.0765(0.0857) Grad: 143925.7344 LR: 0.00000844 \n",
            "Epoch: [4][260/366] Elapsed 17m 6s (remain 6m 52s) Loss: 0.0847(0.0858) Grad: 142036.7344 LR: 0.00000781 \n",
            "Epoch: [4][280/366] Elapsed 18m 20s (remain 5m 32s) Loss: 0.0804(0.0857) Grad: 105533.6016 LR: 0.00000719 \n",
            "Epoch: [4][300/366] Elapsed 19m 32s (remain 4m 13s) Loss: 0.1391(0.0862) Grad: 447262.5312 LR: 0.00000660 \n",
            "Epoch: [4][320/366] Elapsed 20m 49s (remain 2m 55s) Loss: 0.1154(0.0863) Grad: 333580.6250 LR: 0.00000603 \n",
            "Epoch: [4][340/366] Elapsed 22m 9s (remain 1m 37s) Loss: 0.0767(0.0860) Grad: 105853.9141 LR: 0.00000549 \n",
            "Epoch: [4][360/366] Elapsed 23m 31s (remain 0m 19s) Loss: 0.0760(0.0859) Grad: 124396.7031 LR: 0.00000496 \n",
            "Epoch: [4][365/366] Elapsed 23m 51s (remain 0m 0s) Loss: 0.0929(0.0859) Grad: 182134.9062 LR: 0.00000484 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 3m 56s) Loss: 0.1207(0.1207) \n",
            "EVAL: [20/62] Elapsed 0m 46s (remain 1m 30s) Loss: 0.0772(0.1064) \n",
            "EVAL: [40/62] Elapsed 1m 26s (remain 0m 44s) Loss: 0.0992(0.1058) \n",
            "EVAL: [60/62] Elapsed 2m 10s (remain 0m 2s) Loss: 0.0961(0.1070) \n",
            "EVAL: [61/62] Elapsed 2m 10s (remain 0m 0s) Loss: 0.0594(0.1069) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0859  avg_val_loss: 0.1069  time: 1562s\n",
            "INFO:__main__:Epoch 4 - avg_train_loss: 0.0859  avg_val_loss: 0.1069  time: 1562s\n",
            "Epoch 4 - Score: 0.4638  Scores: [0.4805735935995257, 0.45715367978088434, 0.4230368138597974, 0.4676452613520548, 0.48907926441588845, 0.465319987239525]\n",
            "INFO:__main__:Epoch 4 - Score: 0.4638  Scores: [0.4805735935995257, 0.45715367978088434, 0.4230368138597974, 0.4676452613520548, 0.48907926441588845, 0.465319987239525]\n",
            "Epoch 4 - Save Best Score: 0.4638 Model\n",
            "INFO:__main__:Epoch 4 - Save Best Score: 0.4638 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [5][0/366] Elapsed 0m 2s (remain 13m 30s) Loss: 0.0896(0.0896) Grad: 134887.9844 LR: 0.00000481 \n",
            "Epoch: [5][20/366] Elapsed 1m 10s (remain 19m 17s) Loss: 0.0560(0.0767) Grad: 111451.9219 LR: 0.00000432 \n",
            "Epoch: [5][40/366] Elapsed 2m 26s (remain 19m 24s) Loss: 0.0690(0.0770) Grad: 282161.7188 LR: 0.00000385 \n",
            "Epoch: [5][60/366] Elapsed 4m 5s (remain 20m 26s) Loss: 0.0838(0.0794) Grad: 142926.5312 LR: 0.00000340 \n",
            "Epoch: [5][80/366] Elapsed 5m 32s (remain 19m 31s) Loss: 0.0882(0.0830) Grad: 160540.6094 LR: 0.00000298 \n",
            "Epoch: [5][100/366] Elapsed 6m 37s (remain 17m 23s) Loss: 0.1040(0.0816) Grad: 486983.1875 LR: 0.00000259 \n",
            "Epoch: [5][120/366] Elapsed 7m 59s (remain 16m 11s) Loss: 0.0800(0.0808) Grad: 520393.5000 LR: 0.00000222 \n",
            "Epoch: [5][140/366] Elapsed 9m 24s (remain 15m 0s) Loss: 0.0405(0.0800) Grad: 88003.2969 LR: 0.00000188 \n",
            "Epoch: [5][160/366] Elapsed 10m 45s (remain 13m 41s) Loss: 0.1169(0.0796) Grad: 269959.1875 LR: 0.00000157 \n",
            "Epoch: [5][180/366] Elapsed 12m 7s (remain 12m 23s) Loss: 0.0711(0.0796) Grad: 243781.5000 LR: 0.00000129 \n",
            "Epoch: [5][200/366] Elapsed 13m 34s (remain 11m 8s) Loss: 0.1188(0.0801) Grad: 217023.2031 LR: 0.00000103 \n",
            "Epoch: [5][220/366] Elapsed 15m 1s (remain 9m 51s) Loss: 0.0695(0.0799) Grad: 102746.4062 LR: 0.00000080 \n",
            "Epoch: [5][240/366] Elapsed 16m 6s (remain 8m 21s) Loss: 0.1377(0.0798) Grad: 333115.5938 LR: 0.00000060 \n",
            "Epoch: [5][260/366] Elapsed 17m 20s (remain 6m 58s) Loss: 0.1102(0.0793) Grad: 328636.6250 LR: 0.00000043 \n",
            "Epoch: [5][280/366] Elapsed 18m 39s (remain 5m 38s) Loss: 0.0733(0.0793) Grad: 124803.7344 LR: 0.00000028 \n",
            "Epoch: [5][300/366] Elapsed 20m 1s (remain 4m 19s) Loss: 0.0597(0.0788) Grad: 206319.1562 LR: 0.00000017 \n",
            "Epoch: [5][320/366] Elapsed 21m 2s (remain 2m 57s) Loss: 0.0775(0.0785) Grad: 195073.6406 LR: 0.00000008 \n",
            "Epoch: [5][340/366] Elapsed 22m 20s (remain 1m 38s) Loss: 0.0392(0.0782) Grad: 129348.5000 LR: 0.00000003 \n",
            "Epoch: [5][360/366] Elapsed 23m 41s (remain 0m 19s) Loss: 0.0604(0.0778) Grad: 73139.1875 LR: 0.00000000 \n",
            "Epoch: [5][365/366] Elapsed 24m 0s (remain 0m 0s) Loss: 0.0823(0.0781) Grad: 98785.5781 LR: 0.00000000 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 3m 57s) Loss: 0.1209(0.1209) \n",
            "EVAL: [20/62] Elapsed 0m 46s (remain 1m 30s) Loss: 0.0799(0.1054) \n",
            "EVAL: [40/62] Elapsed 1m 26s (remain 0m 44s) Loss: 0.0974(0.1052) \n",
            "EVAL: [60/62] Elapsed 2m 9s (remain 0m 2s) Loss: 0.0982(0.1063) \n",
            "EVAL: [61/62] Elapsed 2m 10s (remain 0m 0s) Loss: 0.0661(0.1062) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0781  avg_val_loss: 0.1062  time: 1570s\n",
            "INFO:__main__:Epoch 5 - avg_train_loss: 0.0781  avg_val_loss: 0.1062  time: 1570s\n",
            "Epoch 5 - Score: 0.4622  Scores: [0.48105048125261346, 0.4568219033373176, 0.42100307629902434, 0.4674648817609515, 0.49004161558671194, 0.45706668651445936]\n",
            "INFO:__main__:Epoch 5 - Score: 0.4622  Scores: [0.48105048125261346, 0.4568219033373176, 0.42100307629902434, 0.4674648817609515, 0.49004161558671194, 0.45706668651445936]\n",
            "Epoch 5 - Save Best Score: 0.4622 Model\n",
            "INFO:__main__:Epoch 5 - Save Best Score: 0.4622 Model\n",
            "========== fold: 2 result ==========\n",
            "INFO:__main__:========== fold: 2 result ==========\n",
            "Score: 0.4622  Scores: [0.48105048125261346, 0.4568219033373176, 0.42100307629902434, 0.4674648817609515, 0.49004161558671194, 0.45706668651445936]\n",
            "INFO:__main__:Score: 0.4622  Scores: [0.48105048125261346, 0.4568219033373176, 0.42100307629902434, 0.4674648817609515, 0.49004161558671194, 0.45706668651445936]\n",
            "========== fold: 3 training ==========\n",
            "INFO:__main__:========== fold: 3 training ==========\n",
            "DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "INFO:__main__:DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/366] Elapsed 0m 4s (remain 28m 33s) Loss: 2.3476(2.3476) Grad: inf LR: 0.00005000 \n",
            "Epoch: [1][20/366] Elapsed 1m 36s (remain 26m 21s) Loss: 0.3687(0.7987) Grad: 380373.5625 LR: 0.00004998 \n",
            "Epoch: [1][40/366] Elapsed 3m 4s (remain 24m 25s) Loss: 0.1190(0.5238) Grad: 204806.7188 LR: 0.00004994 \n",
            "Epoch: [1][60/366] Elapsed 4m 18s (remain 21m 32s) Loss: 0.1953(0.4125) Grad: 134120.1406 LR: 0.00004986 \n",
            "Epoch: [1][80/366] Elapsed 5m 36s (remain 19m 42s) Loss: 0.1328(0.3497) Grad: 178906.9375 LR: 0.00004976 \n",
            "Epoch: [1][100/366] Elapsed 6m 43s (remain 17m 39s) Loss: 0.1242(0.3087) Grad: 98835.9688 LR: 0.00004963 \n",
            "Epoch: [1][120/366] Elapsed 8m 6s (remain 16m 25s) Loss: 0.0872(0.2772) Grad: 130300.9688 LR: 0.00004946 \n",
            "Epoch: [1][140/366] Elapsed 9m 22s (remain 14m 57s) Loss: 0.1017(0.2582) Grad: 127717.7891 LR: 0.00004927 \n",
            "Epoch: [1][160/366] Elapsed 10m 27s (remain 13m 18s) Loss: 0.2384(0.2435) Grad: 381139.2500 LR: 0.00004905 \n",
            "Epoch: [1][180/366] Elapsed 11m 37s (remain 11m 52s) Loss: 0.1077(0.2304) Grad: 136735.2344 LR: 0.00004881 \n",
            "Epoch: [1][200/366] Elapsed 13m 4s (remain 10m 44s) Loss: 0.1572(0.2217) Grad: 89238.4375 LR: 0.00004853 \n",
            "Epoch: [1][220/366] Elapsed 14m 30s (remain 9m 31s) Loss: 0.1490(0.2147) Grad: 153022.5938 LR: 0.00004823 \n",
            "Epoch: [1][240/366] Elapsed 15m 44s (remain 8m 9s) Loss: 0.0891(0.2073) Grad: 96990.3281 LR: 0.00004790 \n",
            "Epoch: [1][260/366] Elapsed 17m 7s (remain 6m 53s) Loss: 0.1111(0.2001) Grad: 127597.8516 LR: 0.00004754 \n",
            "Epoch: [1][280/366] Elapsed 18m 27s (remain 5m 34s) Loss: 0.1059(0.1946) Grad: 111928.6094 LR: 0.00004716 \n",
            "Epoch: [1][300/366] Elapsed 19m 49s (remain 4m 16s) Loss: 0.1186(0.1899) Grad: 129474.7969 LR: 0.00004675 \n",
            "Epoch: [1][320/366] Elapsed 21m 6s (remain 2m 57s) Loss: 0.1171(0.1859) Grad: 122768.0078 LR: 0.00004631 \n",
            "Epoch: [1][340/366] Elapsed 22m 13s (remain 1m 37s) Loss: 0.1134(0.1840) Grad: 178570.6719 LR: 0.00004585 \n",
            "Epoch: [1][360/366] Elapsed 23m 18s (remain 0m 19s) Loss: 0.1470(0.1811) Grad: 162152.5469 LR: 0.00004537 \n",
            "Epoch: [1][365/366] Elapsed 23m 38s (remain 0m 0s) Loss: 0.1875(0.1807) Grad: 390535.8750 LR: 0.00004524 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 3m 53s) Loss: 0.1386(0.1386) \n",
            "EVAL: [20/62] Elapsed 0m 45s (remain 1m 28s) Loss: 0.0839(0.1256) \n",
            "EVAL: [40/62] Elapsed 1m 29s (remain 0m 46s) Loss: 0.1382(0.1299) \n",
            "EVAL: [60/62] Elapsed 2m 12s (remain 0m 2s) Loss: 0.1267(0.1294) \n",
            "EVAL: [61/62] Elapsed 2m 13s (remain 0m 0s) Loss: 0.0556(0.1292) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.1807  avg_val_loss: 0.1292  time: 1551s\n",
            "INFO:__main__:Epoch 1 - avg_train_loss: 0.1807  avg_val_loss: 0.1292  time: 1551s\n",
            "Epoch 1 - Score: 0.5083  Scores: [0.5414886904627174, 0.6176239463079181, 0.4272528286850764, 0.44793986127528906, 0.5148194851538422, 0.500437403723226]\n",
            "INFO:__main__:Epoch 1 - Score: 0.5083  Scores: [0.5414886904627174, 0.6176239463079181, 0.4272528286850764, 0.44793986127528906, 0.5148194851538422, 0.500437403723226]\n",
            "Epoch 1 - Save Best Score: 0.5083 Model\n",
            "INFO:__main__:Epoch 1 - Save Best Score: 0.5083 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/366] Elapsed 0m 6s (remain 41m 12s) Loss: 0.1342(0.1342) Grad: 237246.4219 LR: 0.00004522 \n",
            "Epoch: [2][20/366] Elapsed 1m 36s (remain 26m 28s) Loss: 0.1041(0.1079) Grad: 247701.1562 LR: 0.00004470 \n",
            "Epoch: [2][40/366] Elapsed 2m 42s (remain 21m 27s) Loss: 0.0780(0.1125) Grad: 177643.0781 LR: 0.00004416 \n",
            "Epoch: [2][60/366] Elapsed 4m 11s (remain 20m 58s) Loss: 0.1023(0.1143) Grad: 126812.1250 LR: 0.00004360 \n",
            "Epoch: [2][80/366] Elapsed 5m 35s (remain 19m 38s) Loss: 0.1252(0.1130) Grad: 350605.6250 LR: 0.00004302 \n",
            "Epoch: [2][100/366] Elapsed 6m 55s (remain 18m 10s) Loss: 0.0546(0.1119) Grad: 70540.4062 LR: 0.00004241 \n",
            "Epoch: [2][120/366] Elapsed 8m 9s (remain 16m 30s) Loss: 0.1499(0.1110) Grad: 293992.7500 LR: 0.00004179 \n",
            "Epoch: [2][140/366] Elapsed 9m 33s (remain 15m 15s) Loss: 0.0794(0.1114) Grad: 142403.0781 LR: 0.00004114 \n",
            "Epoch: [2][160/366] Elapsed 10m 48s (remain 13m 45s) Loss: 0.0575(0.1101) Grad: 92118.7422 LR: 0.00004048 \n",
            "Epoch: [2][180/366] Elapsed 12m 16s (remain 12m 32s) Loss: 0.0691(0.1095) Grad: 203118.6094 LR: 0.00003979 \n",
            "Epoch: [2][200/366] Elapsed 13m 28s (remain 11m 3s) Loss: 0.0709(0.1103) Grad: 196624.0156 LR: 0.00003910 \n",
            "Epoch: [2][220/366] Elapsed 14m 37s (remain 9m 35s) Loss: 0.0557(0.1102) Grad: 146816.2188 LR: 0.00003838 \n",
            "Epoch: [2][240/366] Elapsed 16m 3s (remain 8m 19s) Loss: 0.0485(0.1105) Grad: 112982.4297 LR: 0.00003765 \n",
            "Epoch: [2][260/366] Elapsed 17m 16s (remain 6m 56s) Loss: 0.0952(0.1102) Grad: 287381.4062 LR: 0.00003690 \n",
            "Epoch: [2][280/366] Elapsed 18m 25s (remain 5m 34s) Loss: 0.0973(0.1102) Grad: 239342.8125 LR: 0.00003614 \n",
            "Epoch: [2][300/366] Elapsed 19m 28s (remain 4m 12s) Loss: 0.0988(0.1102) Grad: 196854.3906 LR: 0.00003537 \n",
            "Epoch: [2][320/366] Elapsed 20m 39s (remain 2m 53s) Loss: 0.0792(0.1099) Grad: 157441.8125 LR: 0.00003458 \n",
            "Epoch: [2][340/366] Elapsed 21m 55s (remain 1m 36s) Loss: 0.1290(0.1094) Grad: 145833.5625 LR: 0.00003378 \n",
            "Epoch: [2][360/366] Elapsed 22m 58s (remain 0m 19s) Loss: 0.0755(0.1090) Grad: 111708.6172 LR: 0.00003298 \n",
            "Epoch: [2][365/366] Elapsed 23m 21s (remain 0m 0s) Loss: 0.1352(0.1092) Grad: 205826.2969 LR: 0.00003277 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 3m 46s) Loss: 0.0877(0.0877) \n",
            "EVAL: [20/62] Elapsed 0m 45s (remain 1m 28s) Loss: 0.0785(0.1047) \n",
            "EVAL: [40/62] Elapsed 1m 29s (remain 0m 45s) Loss: 0.1294(0.1100) \n",
            "EVAL: [60/62] Elapsed 2m 12s (remain 0m 2s) Loss: 0.0933(0.1115) \n",
            "EVAL: [61/62] Elapsed 2m 12s (remain 0m 0s) Loss: 0.0523(0.1113) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.1092  avg_val_loss: 0.1113  time: 1535s\n",
            "INFO:__main__:Epoch 2 - avg_train_loss: 0.1092  avg_val_loss: 0.1113  time: 1535s\n",
            "Epoch 2 - Score: 0.4727  Scores: [0.5421120556188124, 0.4525918181044998, 0.4701565734212047, 0.45457669602322853, 0.47627616672643824, 0.44057392432378845]\n",
            "INFO:__main__:Epoch 2 - Score: 0.4727  Scores: [0.5421120556188124, 0.4525918181044998, 0.4701565734212047, 0.45457669602322853, 0.47627616672643824, 0.44057392432378845]\n",
            "Epoch 2 - Save Best Score: 0.4727 Model\n",
            "INFO:__main__:Epoch 2 - Save Best Score: 0.4727 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/366] Elapsed 0m 2s (remain 12m 28s) Loss: 0.0833(0.0833) Grad: 156188.7969 LR: 0.00003273 \n",
            "Epoch: [3][20/366] Elapsed 1m 19s (remain 21m 46s) Loss: 0.0642(0.0940) Grad: 117073.0547 LR: 0.00003191 \n",
            "Epoch: [3][40/366] Elapsed 2m 18s (remain 18m 14s) Loss: 0.1293(0.0938) Grad: 118003.7656 LR: 0.00003109 \n",
            "Epoch: [3][60/366] Elapsed 3m 37s (remain 18m 9s) Loss: 0.0808(0.0965) Grad: 289842.5312 LR: 0.00003025 \n",
            "Epoch: [3][80/366] Elapsed 5m 0s (remain 17m 37s) Loss: 0.0895(0.0978) Grad: 175601.3594 LR: 0.00002941 \n",
            "Epoch: [3][100/366] Elapsed 6m 8s (remain 16m 6s) Loss: 0.1206(0.0992) Grad: 342928.5938 LR: 0.00002857 \n",
            "Epoch: [3][120/366] Elapsed 7m 41s (remain 15m 34s) Loss: 0.0921(0.1004) Grad: 196943.1094 LR: 0.00002772 \n",
            "Epoch: [3][140/366] Elapsed 9m 7s (remain 14m 33s) Loss: 0.0857(0.1007) Grad: 308509.3125 LR: 0.00002686 \n",
            "Epoch: [3][160/366] Elapsed 10m 14s (remain 13m 2s) Loss: 0.0962(0.1020) Grad: 276142.0938 LR: 0.00002601 \n",
            "Epoch: [3][180/366] Elapsed 11m 30s (remain 11m 45s) Loss: 0.1069(0.1025) Grad: 241370.5781 LR: 0.00002515 \n",
            "Epoch: [3][200/366] Elapsed 12m 26s (remain 10m 12s) Loss: 0.1107(0.1033) Grad: 180916.3594 LR: 0.00002429 \n",
            "Epoch: [3][220/366] Elapsed 13m 40s (remain 8m 58s) Loss: 0.1865(0.1027) Grad: 813977.5625 LR: 0.00002344 \n",
            "Epoch: [3][240/366] Elapsed 15m 12s (remain 7m 53s) Loss: 0.0977(0.1022) Grad: 262582.6250 LR: 0.00002258 \n",
            "Epoch: [3][260/366] Elapsed 16m 30s (remain 6m 38s) Loss: 0.1073(0.1021) Grad: 130432.8125 LR: 0.00002173 \n",
            "Epoch: [3][280/366] Elapsed 17m 49s (remain 5m 23s) Loss: 0.1371(0.1012) Grad: 327341.3750 LR: 0.00002088 \n",
            "Epoch: [3][300/366] Elapsed 19m 27s (remain 4m 12s) Loss: 0.0758(0.1010) Grad: 88161.2422 LR: 0.00002004 \n",
            "Epoch: [3][320/366] Elapsed 20m 49s (remain 2m 55s) Loss: 0.0639(0.1000) Grad: 121643.4219 LR: 0.00001920 \n",
            "Epoch: [3][340/366] Elapsed 22m 1s (remain 1m 36s) Loss: 0.0733(0.0999) Grad: 116374.4688 LR: 0.00001837 \n",
            "Epoch: [3][360/366] Elapsed 23m 18s (remain 0m 19s) Loss: 0.1182(0.1004) Grad: 259312.8594 LR: 0.00001755 \n",
            "Epoch: [3][365/366] Elapsed 23m 43s (remain 0m 0s) Loss: 0.1058(0.1003) Grad: 284551.8750 LR: 0.00001735 \n",
            "EVAL: [0/62] Elapsed 0m 4s (remain 4m 8s) Loss: 0.1135(0.1135) \n",
            "EVAL: [20/62] Elapsed 0m 45s (remain 1m 28s) Loss: 0.0585(0.1044) \n",
            "EVAL: [40/62] Elapsed 1m 29s (remain 0m 46s) Loss: 0.1138(0.1066) \n",
            "EVAL: [60/62] Elapsed 2m 12s (remain 0m 2s) Loss: 0.0967(0.1059) \n",
            "EVAL: [61/62] Elapsed 2m 13s (remain 0m 0s) Loss: 0.0436(0.1058) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.1003  avg_val_loss: 0.1058  time: 1558s\n",
            "INFO:__main__:Epoch 3 - avg_train_loss: 0.1003  avg_val_loss: 0.1058  time: 1558s\n",
            "Epoch 3 - Score: 0.4611  Scores: [0.48899757604092525, 0.44634853246657347, 0.4298879939098373, 0.46589861382445547, 0.4891564027272441, 0.44619350586786166]\n",
            "INFO:__main__:Epoch 3 - Score: 0.4611  Scores: [0.48899757604092525, 0.44634853246657347, 0.4298879939098373, 0.46589861382445547, 0.4891564027272441, 0.44619350586786166]\n",
            "Epoch 3 - Save Best Score: 0.4611 Model\n",
            "INFO:__main__:Epoch 3 - Save Best Score: 0.4611 Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [4][0/366] Elapsed 0m 6s (remain 41m 46s) Loss: 0.1305(0.1305) Grad: 262257.3125 LR: 0.00001731 \n",
            "Epoch: [4][20/366] Elapsed 1m 20s (remain 21m 59s) Loss: 0.0821(0.0993) Grad: 93087.1953 LR: 0.00001650 \n",
            "Epoch: [4][40/366] Elapsed 2m 31s (remain 20m 4s) Loss: 0.1342(0.0960) Grad: 114302.0078 LR: 0.00001570 \n",
            "Epoch: [4][60/366] Elapsed 3m 52s (remain 19m 23s) Loss: 0.1120(0.0932) Grad: 150924.1719 LR: 0.00001491 \n",
            "Epoch: [4][80/366] Elapsed 5m 15s (remain 18m 28s) Loss: 0.0942(0.0934) Grad: 107176.5391 LR: 0.00001413 \n",
            "Epoch: [4][100/366] Elapsed 6m 32s (remain 17m 10s) Loss: 0.1001(0.0930) Grad: 135739.4062 LR: 0.00001336 \n",
            "Epoch: [4][120/366] Elapsed 7m 46s (remain 15m 45s) Loss: 0.1105(0.0947) Grad: 91071.9062 LR: 0.00001261 \n",
            "Epoch: [4][140/366] Elapsed 9m 10s (remain 14m 38s) Loss: 0.1040(0.0963) Grad: 234212.8594 LR: 0.00001187 \n",
            "Epoch: [4][160/366] Elapsed 10m 35s (remain 13m 29s) Loss: 0.1119(0.0971) Grad: 82647.1641 LR: 0.00001115 \n",
            "Epoch: [4][180/366] Elapsed 11m 59s (remain 12m 14s) Loss: 0.0694(0.0956) Grad: 77812.5859 LR: 0.00001045 \n",
            "Epoch: [4][200/366] Elapsed 13m 16s (remain 10m 54s) Loss: 0.1194(0.0946) Grad: 195440.2812 LR: 0.00000976 \n",
            "Epoch: [4][220/366] Elapsed 14m 34s (remain 9m 33s) Loss: 0.1073(0.0943) Grad: 68027.7344 LR: 0.00000909 \n",
            "Epoch: [4][240/366] Elapsed 15m 48s (remain 8m 12s) Loss: 0.0914(0.0938) Grad: 88918.6250 LR: 0.00000844 \n",
            "Epoch: [4][260/366] Elapsed 17m 0s (remain 6m 50s) Loss: 0.0675(0.0936) Grad: 73967.1562 LR: 0.00000781 \n",
            "Epoch: [4][280/366] Elapsed 18m 5s (remain 5m 28s) Loss: 0.0839(0.0934) Grad: 74037.8281 LR: 0.00000719 \n",
            "Epoch: [4][300/366] Elapsed 19m 34s (remain 4m 13s) Loss: 0.0977(0.0935) Grad: 166814.8438 LR: 0.00000660 \n",
            "Epoch: [4][320/366] Elapsed 20m 57s (remain 2m 56s) Loss: 0.0921(0.0931) Grad: 69694.9766 LR: 0.00000603 \n",
            "Epoch: [4][340/366] Elapsed 22m 17s (remain 1m 38s) Loss: 0.0898(0.0930) Grad: 76466.2656 LR: 0.00000549 \n",
            "Epoch: [4][360/366] Elapsed 23m 22s (remain 0m 19s) Loss: 0.0752(0.0927) Grad: 140826.8438 LR: 0.00000496 \n",
            "Epoch: [4][365/366] Elapsed 23m 43s (remain 0m 0s) Loss: 0.0918(0.0927) Grad: 60423.6641 LR: 0.00000484 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 3m 46s) Loss: 0.1120(0.1120) \n",
            "EVAL: [20/62] Elapsed 0m 45s (remain 1m 28s) Loss: 0.0618(0.1059) \n",
            "EVAL: [40/62] Elapsed 1m 29s (remain 0m 45s) Loss: 0.1029(0.1072) \n",
            "EVAL: [60/62] Elapsed 2m 12s (remain 0m 2s) Loss: 0.1060(0.1069) \n",
            "EVAL: [61/62] Elapsed 2m 12s (remain 0m 0s) Loss: 0.0433(0.1068) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0927  avg_val_loss: 0.1068  time: 1557s\n",
            "INFO:__main__:Epoch 4 - avg_train_loss: 0.0927  avg_val_loss: 0.1068  time: 1557s\n",
            "Epoch 4 - Score: 0.4632  Scores: [0.5041783525542941, 0.44718976734588206, 0.431512110805992, 0.46386026167674177, 0.46682214719534976, 0.46565929125048683]\n",
            "INFO:__main__:Epoch 4 - Score: 0.4632  Scores: [0.5041783525542941, 0.44718976734588206, 0.431512110805992, 0.46386026167674177, 0.46682214719534976, 0.46565929125048683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [5][0/366] Elapsed 0m 2s (remain 14m 31s) Loss: 0.1491(0.1491) Grad: 312498.0625 LR: 0.00000481 \n",
            "Epoch: [5][20/366] Elapsed 1m 12s (remain 19m 43s) Loss: 0.0414(0.0898) Grad: 121221.5859 LR: 0.00000432 \n",
            "Epoch: [5][40/366] Elapsed 2m 36s (remain 20m 40s) Loss: 0.0539(0.0850) Grad: 237305.8281 LR: 0.00000385 \n",
            "Epoch: [5][60/366] Elapsed 4m 3s (remain 20m 16s) Loss: 0.1020(0.0823) Grad: 145323.7500 LR: 0.00000340 \n",
            "Epoch: [5][80/366] Elapsed 5m 30s (remain 19m 21s) Loss: 0.0825(0.0816) Grad: 281929.4688 LR: 0.00000298 \n",
            "Epoch: [5][100/366] Elapsed 6m 49s (remain 17m 53s) Loss: 0.1350(0.0825) Grad: 188197.8750 LR: 0.00000259 \n",
            "Epoch: [5][120/366] Elapsed 8m 14s (remain 16m 40s) Loss: 0.0761(0.0837) Grad: 222539.1250 LR: 0.00000222 \n",
            "Epoch: [5][140/366] Elapsed 9m 38s (remain 15m 22s) Loss: 0.0900(0.0835) Grad: 118217.5078 LR: 0.00000188 \n",
            "Epoch: [5][160/366] Elapsed 10m 46s (remain 13m 42s) Loss: 0.0735(0.0844) Grad: 85036.7109 LR: 0.00000157 \n",
            "Epoch: [5][180/366] Elapsed 11m 51s (remain 12m 7s) Loss: 0.0603(0.0844) Grad: 152545.4531 LR: 0.00000129 \n",
            "Epoch: [5][200/366] Elapsed 13m 15s (remain 10m 52s) Loss: 0.0713(0.0841) Grad: 144588.3438 LR: 0.00000103 \n",
            "Epoch: [5][220/366] Elapsed 14m 33s (remain 9m 32s) Loss: 0.0969(0.0835) Grad: 139042.5156 LR: 0.00000080 \n",
            "Epoch: [5][240/366] Elapsed 15m 33s (remain 8m 4s) Loss: 0.0921(0.0832) Grad: 288513.5312 LR: 0.00000060 \n",
            "Epoch: [5][260/366] Elapsed 16m 54s (remain 6m 48s) Loss: 0.0917(0.0832) Grad: 164440.4062 LR: 0.00000043 \n",
            "Epoch: [5][280/366] Elapsed 18m 3s (remain 5m 27s) Loss: 0.1082(0.0826) Grad: 439780.8750 LR: 0.00000028 \n",
            "Epoch: [5][300/366] Elapsed 19m 14s (remain 4m 9s) Loss: 0.1071(0.0824) Grad: 621053.9375 LR: 0.00000017 \n",
            "Epoch: [5][320/366] Elapsed 20m 23s (remain 2m 51s) Loss: 0.0590(0.0821) Grad: 262674.2188 LR: 0.00000008 \n",
            "Epoch: [5][340/366] Elapsed 21m 53s (remain 1m 36s) Loss: 0.0634(0.0821) Grad: 156630.9531 LR: 0.00000003 \n",
            "Epoch: [5][360/366] Elapsed 23m 1s (remain 0m 19s) Loss: 0.0548(0.0821) Grad: 147563.2188 LR: 0.00000000 \n",
            "Epoch: [5][365/366] Elapsed 23m 22s (remain 0m 0s) Loss: 0.0817(0.0819) Grad: 211721.5625 LR: 0.00000000 \n",
            "EVAL: [0/62] Elapsed 0m 3s (remain 3m 46s) Loss: 0.0903(0.0903) \n",
            "EVAL: [20/62] Elapsed 0m 44s (remain 1m 27s) Loss: 0.0628(0.0977) \n",
            "EVAL: [40/62] Elapsed 1m 29s (remain 0m 45s) Loss: 0.1081(0.1001) \n",
            "EVAL: [60/62] Elapsed 2m 12s (remain 0m 2s) Loss: 0.0925(0.1004) \n",
            "EVAL: [61/62] Elapsed 2m 12s (remain 0m 0s) Loss: 0.0496(0.1003) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0819  avg_val_loss: 0.1003  time: 1536s\n",
            "INFO:__main__:Epoch 5 - avg_train_loss: 0.0819  avg_val_loss: 0.1003  time: 1536s\n",
            "Epoch 5 - Score: 0.4485  Scores: [0.4878341040270054, 0.4440003886070633, 0.4134837642686337, 0.44589989488905724, 0.4679583320867184, 0.4318803907390444]\n",
            "INFO:__main__:Epoch 5 - Score: 0.4485  Scores: [0.4878341040270054, 0.4440003886070633, 0.4134837642686337, 0.44589989488905724, 0.4679583320867184, 0.4318803907390444]\n",
            "Epoch 5 - Save Best Score: 0.4485 Model\n",
            "INFO:__main__:Epoch 5 - Save Best Score: 0.4485 Model\n",
            "========== fold: 3 result ==========\n",
            "INFO:__main__:========== fold: 3 result ==========\n",
            "Score: 0.4485  Scores: [0.4878341040270054, 0.4440003886070633, 0.4134837642686337, 0.44589989488905724, 0.4679583320867184, 0.4318803907390444]\n",
            "INFO:__main__:Score: 0.4485  Scores: [0.4878341040270054, 0.4440003886070633, 0.4134837642686337, 0.44589989488905724, 0.4679583320867184, 0.4318803907390444]\n",
            "========== CV ==========\n",
            "INFO:__main__:========== CV ==========\n",
            "Score: 0.4556  Scores: [0.4850026218669962, 0.4491783396376053, 0.4176323654614873, 0.45670170848351505, 0.47716697506366673, 0.4478289903604743]\n",
            "INFO:__main__:Score: 0.4556  Scores: [0.4850026218669962, 0.4491783396376053, 0.4176323654614873, 0.45670170848351505, 0.47716697506366673, 0.4478289903604743]\n"
          ]
        }
      ],
      "source": [
        "def get_result(oof_df, fold, best_train_loss, best_val_loss):\n",
        "    labels = oof_df[CFG.target_cols].values\n",
        "    preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
        "    score, scores = get_score(labels, preds)\n",
        "    LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
        "    _output_log = pd.DataFrame([CFG.identifier, CFG.model, CFG.cv_seed, CFG.seed, fold, 'best', score, best_train_loss, best_val_loss] + scores).T\n",
        "    _output_log.columns = ['file', 'model', 'cv_seed', 'seed', 'fold', 'epoch', 'MCRMSE', 'train_loss', 'val_loss'] + CFG.target_cols\n",
        "    return _output_log\n",
        "\n",
        "# デフォルトTrue\n",
        "if CFG.train:\n",
        "    output_log = pd.DataFrame()\n",
        "    oof_df = pd.DataFrame()\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    for fold in range(CFG.n_fold):\n",
        "        if fold in CFG.trn_fold:\n",
        "            best_train_loss, best_val_loss, _oof_df, df_epoch_scores = train_loop(CFG.df_train, fold)\n",
        "            train_loss_list.append(best_train_loss)\n",
        "            val_loss_list.append(best_val_loss)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "\n",
        "            df_epoch_scores['file'] = CFG.identifier\n",
        "            df_epoch_scores['model'] = CFG.model\n",
        "            df_epoch_scores['cv_seed'] = CFG.cv_seed\n",
        "            df_epoch_scores['seed'] = CFG.seed\n",
        "            df_epoch_scores['fold'] = fold\n",
        "            df_epoch_scores = df_epoch_scores[['file', 'model', 'cv_seed', 'seed', 'fold', 'epoch', 'MCRMSE', 'train_loss', 'val_loss'] + CFG.target_cols]\n",
        "\n",
        "            _output_log = get_result(_oof_df, fold, best_train_loss, best_val_loss)\n",
        "            output_log = pd.concat([output_log, df_epoch_scores, _output_log])\n",
        "\n",
        "    oof_df = oof_df.reset_index(drop=True)\n",
        "    LOGGER.info(f\"========== CV ==========\")\n",
        "    _output_log = get_result(oof_df, 'OOF', np.mean(train_loss_list), np.mean(val_loss_list))\n",
        "    output_log = pd.concat([output_log, _output_log])\n",
        "    output_log.to_csv(f'{CFG.identifier}.csv', index=False)\n",
        "    oof_df.to_pickle(CFG.OUTPUT_DIR+'oof_df.pkl', protocol = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dOnsyCFb53Et",
      "metadata": {
        "id": "dOnsyCFb53Et"
      },
      "source": [
        "# 作成したモデルをdatasetにアップロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qpyiS7ouaycE",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qpyiS7ouaycE"
      },
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# # %cdで/rootに移動できる。/root/.kaggle にkaggle.jsonを配置しなくてはいけないっぽいから、/root/.kaggleディレクトリ作って、そこにkaggle.jsonを配置して、その後もとの/contentに戻っている\n",
        "# %cd\n",
        "# !mkdir .kaggle\n",
        "# !cp /content/drive/MyDrive/kaggle.json .kaggle/\n",
        "# %cd /content\n",
        "\n",
        "# # 環境変数設定\n",
        "# %env KAGGLE_USERNAME=\"\"\n",
        "\n",
        "# PRETRAIN_DIR = Path(CFG.OUTPUT_DIR)\n",
        "# api = KaggleApi()\n",
        "# api.authenticate()\n",
        "# # dataset-metadata.jsonを作成\n",
        "# api.dataset_initialize_cli(folder=PRETRAIN_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sb1XluI32L0X",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sb1XluI32L0X",
        "outputId": "a8e4a2da-e8b4-4e28-c301-33f38d1d36d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping folder: tokenizer; use '--dir-mode' to upload folders\n",
            "Starting upload for file train.log\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.55k/9.55k [00:02<00:00, 4.26kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload successful: train.log (10KB)\n",
            "Starting upload for file microsoft-deberta-v3-base_fold0_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 704M/704M [00:28<00:00, 25.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload successful: microsoft-deberta-v3-base_fold0_best.pth (704MB)\n",
            "Skipping folder: config; use '--dir-mode' to upload folders\n",
            "Skipping folder: model; use '--dir-mode' to upload folders\n",
            "Starting upload for file microsoft-deberta-v3-base_fold2_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 704M/704M [00:23<00:00, 31.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload successful: microsoft-deberta-v3-base_fold2_best.pth (704MB)\n",
            "Starting upload for file oof_df.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.09M/9.09M [00:02<00:00, 3.55MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload successful: oof_df.pkl (9MB)\n",
            "Starting upload for file microsoft-deberta-v3-base_fold3_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 704M/704M [00:27<00:00, 26.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload successful: microsoft-deberta-v3-base_fold3_best.pth (704MB)\n",
            "Starting upload for file microsoft-deberta-v3-base_fold1_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 704M/704M [00:24<00:00, 30.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload successful: microsoft-deberta-v3-base_fold1_best.pth (704MB)\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "# ID = ‘’\n",
        "\n",
        "UPLOAD_DIR = CFG.OUTPUT_DIR\n",
        "# UPLOAD_DIR = \"/content/sample_data/\"\n",
        "\n",
        "# EX_NO = CFG.identifier\n",
        "EX_NO = \"fb3-miz-single\"\n",
        "\n",
        "# EX_NO = '<実験番号>'  # 実験番号などを入れる、folderのpathにする\n",
        "# USERID = ''\n",
        "\n",
        "\n",
        "def dataset_upload():\n",
        "    import json\n",
        "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "    kaggle_username = os.environ[\"KAGGLE_USERNAME\"]\n",
        "    id = f'{kaggle_username}/{EX_NO}'\n",
        "\n",
        "\n",
        "    dataset_metadata = {}\n",
        "    #dataset_metadata['id'] = id\n",
        "    dataset_metadata['id'] = f'{kaggle_username}/{EX_NO}'\n",
        "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
        "    dataset_metadata['title'] = f'{EX_NO}'\n",
        "\n",
        "    with open(UPLOAD_DIR + 'dataset-metadata.json', 'w') as f:\n",
        "        json.dump(dataset_metadata, f, indent=4)\n",
        "\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    # # データセットがない場合\n",
        "    # なぜかapi.dataset_listで「fb3-miz-single」のdatasetが取得できない。。。\n",
        "    # if f'{kaggle_username}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=kaggle_username, search=f'\"{EX_NO}\"')]:\n",
        "    #     api.dataset_create_new(folder=UPLOAD_DIR,\n",
        "    #                            convert_to_csv=False,\n",
        "    #                            dir_mode='skip')\n",
        "    # # データセットがある場合\n",
        "    # else:\n",
        "    #     api.dataset_create_version(folder=UPLOAD_DIR,\n",
        "    #                                version_notes=f\"{ver_title} MCRMSE: {_output_log.MCRMSE[0]:.10f}\",\n",
        "    #                                convert_to_csv=False,\n",
        "    #                                delete_old_versions=True,\n",
        "    #                                dir_mode='skip')\n",
        "\n",
        "    api.dataset_create_version(folder=UPLOAD_DIR,\n",
        "                                version_notes=f\"{ver_title} MMSE: {_output_log.MCRMSE[0]:.10f}\",\n",
        "                                convert_to_csv=False,\n",
        "                                delete_old_versions=False,\n",
        "                                dir_mode='skip')\n",
        "\n",
        "    # api.dataset_create_version(folder=UPLOAD_DIR,\n",
        "    #                             version_notes=f\"test upload\",\n",
        "    #                             convert_to_csv=False,\n",
        "    #                             delete_old_versions=False,\n",
        "    #                             dir_mode='skip')\n",
        "\n",
        "dataset_upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jWQ5NUsRIX04",
      "metadata": {
        "id": "jWQ5NUsRIX04"
      },
      "outputs": [],
      "source": [
        "print(\"完了しました！！！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aiuxJddbWPWa",
      "metadata": {
        "id": "aiuxJddbWPWa"
      },
      "outputs": [],
      "source": [
        "# def beep():\n",
        "#   from google.colab import output\n",
        "#   output.eval_js('new Audio(\\\n",
        "# \"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\")\\\n",
        "# .play()') \n",
        "\n",
        "# beep()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xyDkRrxC0_af",
      "metadata": {
        "id": "xyDkRrxC0_af"
      },
      "outputs": [],
      "source": [
        "# 全ての実行が終了したら、ランタイムを切断する。（GPU使用時間節約）\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6wYjxromr1SC",
      "metadata": {
        "id": "6wYjxromr1SC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 15026.407319,
      "end_time": "2022-11-03T19:41:21.966107",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-11-03T15:30:55.558788",
      "version": "2.3.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06abc8e28e0d481984df32a0a99182ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072caa0408e347a49827eda8798aae95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad8f7ab685c4044b7f951f3ca457d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_072caa0408e347a49827eda8798aae95",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c8015d529b34934af7099e14f4bfacb",
            "value": 579
          }
        },
        "1858949da150465d85e1e728b424b727": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adc9f11a76534f7b9e782404a3391ce0",
              "IPY_MODEL_96d9ee54c5014823831efd002cc564ff",
              "IPY_MODEL_e8e25b0a58384baaa55eac9bda629219"
            ],
            "layout": "IPY_MODEL_3aaba1da28754b1ca3ecde91528517e5"
          }
        },
        "218275b6c2db4bbb867f8da88063384c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e20673ca67df4da19cf118956f871430",
            "placeholder": "​",
            "style": "IPY_MODEL_64e2011322ce4128891284dd0266aadc",
            "value": "Downloading config.json: 100%"
          }
        },
        "262b110535ec46e3943ccd3f8ab740c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf7dc8cea534808aa078dac35580e6c",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_524df59c90f64d47ab4404b4284814d0",
            "value": 52
          }
        },
        "293b8aa1ac3d4c69997b6e04b71248c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ec634fb54a246809f1070ec7541f56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e75470b17f46b9a3c758347f445d61",
            "placeholder": "​",
            "style": "IPY_MODEL_45812dca1c4b4fd7b20c1aaa772fab77",
            "value": " 579/579 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "2ff59bf8c66749a599478ea12f493ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311a383e1ff64a40ad926fc2b1611e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aaba1da28754b1ca3ecde91528517e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b16e5b663e44c6cb81619ce8bee0a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fd76c8051fd4fffaa22267911bf1bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c97cb70bfa42419adad3e1fecb409f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439a9bea298441218c50bfcda8a79404": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f1951306a745c7be72f1b3a8bbddf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45812dca1c4b4fd7b20c1aaa772fab77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c70554620f240f1a571b5b881c5104d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d08622901ff42e690b0fa700a4f8e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff59bf8c66749a599478ea12f493ff6",
            "max": 3911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fce09eb7df104082b9b614c019b58c0a",
            "value": 3911
          }
        },
        "4ec7c1bae928403aa1da5e2eb3b01497": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "524df59c90f64d47ab4404b4284814d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53aa12e301d241c6a584f0838bc3204c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "592a61a9c9db4b79aa105fb78d7bfb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64e2011322ce4128891284dd0266aadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66117190a25149678437bc74a42abf3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8015d529b34934af7099e14f4bfacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70e75470b17f46b9a3c758347f445d61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75cbcd33cc7b4012885174000f5d6800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "787e8c3524e8480d8191f5677c7665bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e26aa784639d467db5b52de33838e7af",
              "IPY_MODEL_dc377c6426d94b21b7e68161919b87f2",
              "IPY_MODEL_7b310e168ae942fb94eae855723b371b"
            ],
            "layout": "IPY_MODEL_311a383e1ff64a40ad926fc2b1611e6c"
          }
        },
        "7a0379af26344c8aba544ec49b753e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b310e168ae942fb94eae855723b371b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb480d92bef14da490c43b8210a4404a",
            "placeholder": "​",
            "style": "IPY_MODEL_f94b16f095bf4b8fb00f7fdbef6d143b",
            "value": " 354M/354M [00:09&lt;00:00, 21.9MB/s]"
          }
        },
        "7bf7dc8cea534808aa078dac35580e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e3e7d707724a4c9fa8e8475145dc40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8976becc7af74ff3aee13bd76df0f567": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96534e14e146422186b36e758bac95c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_218275b6c2db4bbb867f8da88063384c",
              "IPY_MODEL_0ad8f7ab685c4044b7f951f3ca457d0d",
              "IPY_MODEL_2ec634fb54a246809f1070ec7541f56b"
            ],
            "layout": "IPY_MODEL_86e3e7d707724a4c9fa8e8475145dc40"
          }
        },
        "96d9ee54c5014823831efd002cc564ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c74f8d25b34b8fbe8135617ec29676",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a0379af26344c8aba544ec49b753e16",
            "value": 2464616
          }
        },
        "a436db7162134ca3a5c2aa0f917a2d53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c74f8d25b34b8fbe8135617ec29676": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc9f11a76534f7b9e782404a3391ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66117190a25149678437bc74a42abf3c",
            "placeholder": "​",
            "style": "IPY_MODEL_3b16e5b663e44c6cb81619ce8bee0a69",
            "value": "Downloading spm.model: 100%"
          }
        },
        "b0d0263510864d2fbd0de47b2d980d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8cf425228da4bd38d29b754e7ef782f",
              "IPY_MODEL_262b110535ec46e3943ccd3f8ab740c1",
              "IPY_MODEL_f0ed1eaf8a24470aaa267e63fee7b677"
            ],
            "layout": "IPY_MODEL_4c70554620f240f1a571b5b881c5104d"
          }
        },
        "b1741ddb23a944e5a02be4afba90aae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f1951306a745c7be72f1b3a8bbddf9",
            "placeholder": "​",
            "style": "IPY_MODEL_4ec7c1bae928403aa1da5e2eb3b01497",
            "value": "100%"
          }
        },
        "bfd701991a6448d1a81a146bf3cebc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1526de4d45240f8b610fde11a72bb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1741ddb23a944e5a02be4afba90aae3",
              "IPY_MODEL_4d08622901ff42e690b0fa700a4f8e08",
              "IPY_MODEL_dc64a9d4949542ceb1b77ab075669b18"
            ],
            "layout": "IPY_MODEL_fcc9d7273bc446439c520025e69316dd"
          }
        },
        "cb480d92bef14da490c43b8210a4404a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc377c6426d94b21b7e68161919b87f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f370612454734f7a821d4de60311e2fe",
            "max": 371146213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75cbcd33cc7b4012885174000f5d6800",
            "value": 371146213
          }
        },
        "dc64a9d4949542ceb1b77ab075669b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a436db7162134ca3a5c2aa0f917a2d53",
            "placeholder": "​",
            "style": "IPY_MODEL_bfd701991a6448d1a81a146bf3cebc04",
            "value": " 3911/3911 [00:12&lt;00:00, 364.15it/s]"
          }
        },
        "e20673ca67df4da19cf118956f871430": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26aa784639d467db5b52de33838e7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd76c8051fd4fffaa22267911bf1bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_8976becc7af74ff3aee13bd76df0f567",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "e8cf425228da4bd38d29b754e7ef782f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_439a9bea298441218c50bfcda8a79404",
            "placeholder": "​",
            "style": "IPY_MODEL_293b8aa1ac3d4c69997b6e04b71248c2",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "e8e25b0a58384baaa55eac9bda629219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06abc8e28e0d481984df32a0a99182ff",
            "placeholder": "​",
            "style": "IPY_MODEL_592a61a9c9db4b79aa105fb78d7bfb93",
            "value": " 2.35M/2.35M [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "f0ed1eaf8a24470aaa267e63fee7b677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c97cb70bfa42419adad3e1fecb409f",
            "placeholder": "​",
            "style": "IPY_MODEL_53aa12e301d241c6a584f0838bc3204c",
            "value": " 52.0/52.0 [00:00&lt;00:00, 1.35kB/s]"
          }
        },
        "f370612454734f7a821d4de60311e2fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f94b16f095bf4b8fb00f7fdbef6d143b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcc9d7273bc446439c520025e69316dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce09eb7df104082b9b614c019b58c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
